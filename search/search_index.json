{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OKAPI: Genetic Programming for Ensemble Model Fusion","text":"<p>OKAPI is a Python library that uses genetic programming to evolve optimal ensembles of machine learning models for classification tasks. It combines the predictions of multiple models into a single, more accurate prediction by evolving tree structures representing different fusion strategies.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Tree-based representation: Models ensemble architectures as trees with models as leaves and fusion operations as nodes</li> <li>Evolutionary optimization: Uses genetic programming with crossover and mutation operations to find optimal fusion strategies</li> <li>Multiple fusion operations: Supports mean, min, max, weighted mean, and other operations to combine predictions</li> <li>Backend flexibility: Works with both NumPy and PyTorch backends</li> <li>Pareto optimization: Balances model complexity and performance for robust solutions</li> </ul>"},{"location":"#when-to-use-okapi","title":"When to Use OKAPI","text":"<p>OKAPI is particularly useful when:</p> <ul> <li>You have multiple models predicting the same target</li> <li>You want to combine these models in a way that outperforms individual models</li> <li>You need interpretable fusion structures that show how models are combined</li> <li>You want to automatically discover which models are most useful for your task</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>OKAPI is currently under active development. The core functionality is implemented, but the library may change significantly before the first stable release.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>API Reference: Detailed documentation for all classes and functions in the library</li> <li>Development: Information for contributors interested in helping with the development</li> </ul>"},{"location":"api/backend/","title":"Backend API","text":"<p>This section documents the backend components of OKAPI, which handle tensor operations.</p>"},{"location":"api/backend/#backend-interface","title":"Backend Interface","text":"<p>The abstract interface that all backend implementations must follow.</p> <pre><code>from okapi.backend.backend_interface import BackendInterface\n</code></pre> <p>Abstract interface for tensor backends used by OKAPI.</p> <p>This interface defines the tensor operations required by OKAPI, allowing for different backend implementations (e.g., NumPy, PyTorch) to be used interchangeably. Each backend must implement all these methods to provide a consistent interface for tensor operations.</p> Source code in <code>okapi/backend/backend_interface.py</code> <pre><code>class BackendInterface:\n    \"\"\"\n    Abstract interface for tensor backends used by OKAPI.\n\n    This interface defines the tensor operations required by OKAPI, allowing\n    for different backend implementations (e.g., NumPy, PyTorch) to be used\n    interchangeably. Each backend must implement all these methods to provide\n    a consistent interface for tensor operations.\n    \"\"\"\n\n    @staticmethod\n    def tensor(x):\n        raise NotImplementedError()\n\n    @staticmethod\n    def concat(tensors, axis=0):\n        raise NotImplementedError()\n\n    @staticmethod\n    def mean(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def max(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def min(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def sum(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def argmax(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def argmin(x, axis=None):\n        raise NotImplementedError()\n\n    @staticmethod\n    def to_numpy(x) -&gt; np.ndarray:\n        raise NotImplementedError()\n\n    @staticmethod\n    def clip(x, min, max):\n        raise NotImplementedError()\n\n    @staticmethod\n    def log(x):\n        raise NotImplementedError()\n\n    @staticmethod\n    def to_float(x):\n        raise NotImplementedError()\n\n    @staticmethod\n    def shape(x):\n        raise NotImplementedError()\n\n    @staticmethod\n    def reshape(x, *args, **kwargs):\n        raise NotImplementedError()\n\n    @staticmethod\n    def squeeze(x):\n        raise NotImplementedError()\n\n    @staticmethod\n    def unsqueeze(x, axis):\n        raise NotImplementedError()\n\n    @staticmethod\n    def load(path, device=None):\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/backend/#backend-factory","title":"Backend Factory","text":"<p>Factory class for managing tensor backends.</p> <pre><code>from okapi.backend.backend import Backend\n</code></pre> <p>Factory class for managing tensor backends in OKAPI.</p> <p>This class provides a centralized way to set and retrieve the tensor backend implementation (NumPy or PyTorch) used throughout the OKAPI library.</p> <p>Important: The backend should only be set at the beginning of the program, before any OKAPI instances are initialized or predictions are loaded.</p> Source code in <code>okapi/backend/backend.py</code> <pre><code>class Backend:\n    \"\"\"\n    Factory class for managing tensor backends in OKAPI.\n\n    This class provides a centralized way to set and retrieve the tensor backend\n    implementation (NumPy or PyTorch) used throughout the OKAPI library.\n\n    Important: The backend should only be set at the beginning of the program,\n    before any OKAPI instances are initialized or predictions are loaded.\n    \"\"\"\n\n    _current_backend: Type[BackendInterface] = NumpyBackend\n\n    @classmethod\n    def set_backend(cls, backend_name: str):  # TODO: Add option to set backend by providing class instead\n        \"\"\"\n        Set the active tensor backend by name.\n\n        Available backends:\n        - 'numpy': Uses NumPyBackend for tensor operations\n        - 'torch' or 'pytorch': Uses PyTorchBackend for tensor operations\n\n        Args:\n            backend_name: String identifier for the backend\n\n        Raises:\n            ValueError: If the backend name is not recognized\n        \"\"\"\n        logger.info(f\"Setting tensor backend to '{backend_name}'\")\n        if backend_name == \"torch\" or backend_name == \"pytorch\":\n            from okapi.backend.pytorch import PyTorchBackend\n\n            cls._current_backend = PyTorchBackend\n            logger.debug(\"PyTorch backend initialized successfully\")\n        elif backend_name == \"numpy\":\n            cls._current_backend = NumpyBackend\n            logger.debug(\"NumPy backend initialized successfully\")\n        else:\n            logger.error(f\"Invalid backend: {backend_name}\")\n            raise ValueError(f\"Invalid backend: {backend_name}\")\n\n    @classmethod\n    def get_backend(cls) -&gt; Type[BackendInterface]:\n        \"\"\"\n        Get the current tensor backend.\n\n        Returns:\n            The current backend implementation class (NumpyBackend or PyTorchBackend)\n        \"\"\"\n        logger.trace(f\"Getting current backend: {cls._current_backend.__name__}\")\n        return cls._current_backend\n\n    def __init__(self):\n        pass\n\n    def __getattr__(self, name):\n        return getattr(Backend._current_backend, name)\n</code></pre>"},{"location":"api/backend/#okapi.backend.backend.Backend.get_backend","title":"<code>get_backend()</code>  <code>classmethod</code>","text":"<p>Get the current tensor backend.</p> <p>Returns:</p> Type Description <code>Type[BackendInterface]</code> <p>The current backend implementation class (NumpyBackend or PyTorchBackend)</p> Source code in <code>okapi/backend/backend.py</code> <pre><code>@classmethod\ndef get_backend(cls) -&gt; Type[BackendInterface]:\n    \"\"\"\n    Get the current tensor backend.\n\n    Returns:\n        The current backend implementation class (NumpyBackend or PyTorchBackend)\n    \"\"\"\n    logger.trace(f\"Getting current backend: {cls._current_backend.__name__}\")\n    return cls._current_backend\n</code></pre>"},{"location":"api/backend/#okapi.backend.backend.Backend.set_backend","title":"<code>set_backend(backend_name)</code>  <code>classmethod</code>","text":"<p>Set the active tensor backend by name.</p> <p>Available backends: - 'numpy': Uses NumPyBackend for tensor operations - 'torch' or 'pytorch': Uses PyTorchBackend for tensor operations</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>String identifier for the backend</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the backend name is not recognized</p> Source code in <code>okapi/backend/backend.py</code> <pre><code>@classmethod\ndef set_backend(cls, backend_name: str):  # TODO: Add option to set backend by providing class instead\n    \"\"\"\n    Set the active tensor backend by name.\n\n    Available backends:\n    - 'numpy': Uses NumPyBackend for tensor operations\n    - 'torch' or 'pytorch': Uses PyTorchBackend for tensor operations\n\n    Args:\n        backend_name: String identifier for the backend\n\n    Raises:\n        ValueError: If the backend name is not recognized\n    \"\"\"\n    logger.info(f\"Setting tensor backend to '{backend_name}'\")\n    if backend_name == \"torch\" or backend_name == \"pytorch\":\n        from okapi.backend.pytorch import PyTorchBackend\n\n        cls._current_backend = PyTorchBackend\n        logger.debug(\"PyTorch backend initialized successfully\")\n    elif backend_name == \"numpy\":\n        cls._current_backend = NumpyBackend\n        logger.debug(\"NumPy backend initialized successfully\")\n    else:\n        logger.error(f\"Invalid backend: {backend_name}\")\n        raise ValueError(f\"Invalid backend: {backend_name}\")\n</code></pre>"},{"location":"api/backend/#global-backend-configuration","title":"Global Backend Configuration","text":"<p>Functions and variables for configuring the backend.</p> <pre><code>from okapi.globals import BACKEND, set_backend, get_backend, DEVICE\n</code></pre>"},{"location":"api/backend/#okapi.globals.BACKEND","title":"<code>BACKEND = Backend()</code>  <code>module-attribute</code>","text":""},{"location":"api/backend/#okapi.globals.DEVICE","title":"<code>DEVICE = os.environ.get('DEVICE', None)</code>  <code>module-attribute</code>","text":""},{"location":"api/backend/#okapi.globals.set_backend","title":"<code>set_backend(backend_name)</code>","text":"<p>Set the tensor backend to use.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <p>Name of the backend to use ('numpy' or 'pytorch')</p> required Source code in <code>okapi/globals.py</code> <pre><code>def set_backend(backend_name):\n    \"\"\"\n    Set the tensor backend to use.\n\n    Args:\n        backend_name: Name of the backend to use ('numpy' or 'pytorch')\n    \"\"\"\n    global Backend\n    logger.info(f\"Setting tensor backend to: {backend_name}\")\n    Backend.set_backend(backend_name)\n</code></pre>"},{"location":"api/backend/#okapi.globals.get_backend","title":"<code>get_backend()</code>","text":"<p>Get the current tensor backend.</p> <p>Returns:</p> Type Description <p>The current backend interface class</p> Source code in <code>okapi/globals.py</code> <pre><code>def get_backend():\n    \"\"\"\n    Get the current tensor backend.\n\n    Returns:\n        The current backend interface class\n    \"\"\"\n    global Backend\n    backend = Backend.get_backend()\n    logger.debug(f\"Retrieved current backend: {backend.__name__}\")\n    return backend\n</code></pre>"},{"location":"api/core/","title":"Core API","text":"<p>This section documents the core components of OKAPI.</p>"},{"location":"api/core/#okapi-class","title":"Okapi Class","text":"<p>The <code>Okapi</code> class is the main entry point for evolutionary model ensemble optimization.</p> <pre><code>from okapi import Okapi\n</code></pre> <p>Main class for evolutionary model ensemble optimization.</p> <p>Okapi uses genetic programming to evolve tree-based ensembles of machine learning models. The algorithm creates a population of trees where each tree represents a different way of combining model predictions. Through evolution (crossover and mutation), it searches for optimal ensemble structures that maximize a fitness function.</p> <p>Each tree has ValueNodes that contain tensor predictions from individual models, and OperatorNodes that define how to combine these predictions (e.g., mean, min, max, weighted mean). The evolution process selects and combines high-performing trees to produce better ensembles.</p> <p>Attributes:</p> Name Type Description <code>population_size</code> <p>Number of individuals in the population</p> <code>population_multiplier</code> <p>Factor determining how many additional trees to generate in each iteration</p> <code>tournament_size</code> <p>Number of trees to consider in tournament selection</p> <code>fitness_function</code> <p>Function used to evaluate the fitness of each tree</p> <code>callbacks</code> <p>Collection of callbacks for monitoring/modifying the evolution process</p> <code>allowed_ops</code> <p>Operator node types allowed in tree construction</p> <code>train_tensors</code> <p>Dictionary mapping model names to their prediction tensors</p> <code>gt_tensor</code> <p>Ground truth tensor for comparison</p> <code>population</code> <p>Current population of trees</p> <code>additional_population</code> <code>List[Tree]</code> <p>Additional trees generated during evolution</p> Source code in <code>okapi/okapi.py</code> <pre><code>class Okapi:\n    \"\"\"\n    Main class for evolutionary model ensemble optimization.\n\n    Okapi uses genetic programming to evolve tree-based ensembles of machine learning models.\n    The algorithm creates a population of trees where each tree represents a different way of\n    combining model predictions. Through evolution (crossover and mutation), it searches for\n    optimal ensemble structures that maximize a fitness function.\n\n    Each tree has ValueNodes that contain tensor predictions from individual models, and\n    OperatorNodes that define how to combine these predictions (e.g., mean, min, max, weighted mean).\n    The evolution process selects and combines high-performing trees to produce better ensembles.\n\n    Attributes:\n        population_size: Number of individuals in the population\n        population_multiplier: Factor determining how many additional trees to generate in each iteration\n        tournament_size: Number of trees to consider in tournament selection\n        fitness_function: Function used to evaluate the fitness of each tree\n        callbacks: Collection of callbacks for monitoring/modifying the evolution process\n        allowed_ops: Operator node types allowed in tree construction\n        train_tensors: Dictionary mapping model names to their prediction tensors\n        gt_tensor: Ground truth tensor for comparison\n        population: Current population of trees\n        additional_population: Additional trees generated during evolution\n    \"\"\"\n\n    def __init__(\n        self,\n        preds_source: Union[Path, str, Iterable[Path], Iterable[str]],\n        gt_path: Union[Path, str, Iterable[Path], Iterable[str]],\n        population_size: int,\n        population_multiplier: int,\n        tournament_size: int,\n        minimize_node_count: bool = True,\n        objective_functions: Sequence[Callable[[Tree, lib_types.Tensor], float]] = (average_precision_fitness,),\n        objectives: Sequence[Callable[[float, float], bool]] = (maximize,),\n        allowed_ops: Sequence[Type[OperatorNode]] = (MEAN, MIN, MAX, WEIGHTED_MEAN, FAR_THRESHOLD, CLOSE_THRESHOLD),\n        callbacks: Iterable[Callback] = tuple(),\n        backend: Union[str, None] = None,\n        seed: int = 0,\n        postprocessing_function=None,\n    ):\n        \"\"\"\n        Initialize the Okapi evolutionary algorithm.\n\n        Args:\n            preds_source: Source of model predictions, can be a path to directory or iterable of paths\n            gt_path: Path to ground truth data, can be a single path or iterable of paths. Should match preds_source by order\n            population_size: Size of the population to evolve\n            population_multiplier: Factor determining how many additional trees to generate\n            tournament_size: Number of trees to consider in tournament selection\n            minimize_node_count: Whether the pareto frontier models should also consider node count.\n            objective_functions: Functions that calculate the fitnesses that are to be optimized\n            objectives: Functions that copare two fitnesses and return True if first is better than second. Usually maximize or minimize\n            allowed_ops: Sequence of operator node types that can be used in trees\n            callbacks: Iterable of callback objects for monitoring/modifying evolution\n            backend: Optional backend implementation for tensor operations\n            seed: Random seed for reproducibility\n            postprocessing_function: Function applied after each Op Node.\n            Most of the operations may break some data characteristics, for example vector summing to one. This can be used to fix that.\n        \"\"\"\n        # Validate parameters\n        if population_size &lt;= 0:\n            raise ValueError(f\"population_size must be positive, got {population_size}\")\n        if population_multiplier &lt;= 0:\n            raise ValueError(f\"population_multiplier must be positive, got {population_multiplier}\")\n        if tournament_size &lt;= 0:\n            raise ValueError(f\"tournament_size must be positive, got {tournament_size}\")\n        if tournament_size &gt; population_size:\n            raise ValueError(\n                f\"tournament_size ({tournament_size}) cannot be larger than population_size ({population_size})\"\n            )\n\n        if backend is not None:\n            Backend.set_backend(backend)\n        if seed is not None:\n            np.random.seed(seed)\n        if postprocessing_function:\n            set_postprocessing_function(postprocessing_function)\n\n        self.population_size = population_size\n        self.population_multiplier = population_multiplier\n        self.tournament_size = tournament_size\n        self.minimize_node_count = minimize_node_count\n        self.seed = seed\n\n        self.objective_functions = objective_functions\n        self.objectives = objectives\n        assert len(objectives) == len(objective_functions), \"The number of (optimization) objectives and objective functions is not the same\"\n        self.optimal_point = _get_optimal_point_based_on_list_of_objective_functions(self.objectives)\n\n        self.callbacks = callbacks\n        self.allowed_ops = allowed_ops\n\n        self.train_tensors, self.gt_tensor = self._build_train_tensors(preds_source, gt_path)\n        self.ids, self.models = list(self.train_tensors.keys()), list(self.train_tensors.values())\n        self._validate_input()\n\n        # state\n        self.should_stop = False\n\n        self.population = self._initialize_population()\n        self.additional_population: List[Tree] = []  # for potential callbacks\n        self.fitnesses: None | npt.NDArray[np.float64] = None\n\n    def _call_hook(self, hook_name):\n        \"\"\"\n        Call a specific hook on all registered callbacks.\n\n        Args:\n            hook_name: Name of the hook to call\n        \"\"\"\n        for callback in self.callbacks:\n            getattr(callback, hook_name)(self)\n\n    def _initialize_population(self):\n        \"\"\"\n        Initialize the population of trees.\n\n        Creates simple trees using available prediction tensors.\n\n        Returns:\n            List of initialized Tree objects\n        \"\"\"\n        logger.info(f\"Initializing population with size {self.population_size}\")\n        population = initialize_individuals(self.train_tensors, self.population_size)\n        logger.debug(f\"Population initialized with {len(population)} individuals\")\n        return population\n\n    def _calculate_fitnesses(self, trees: None | List[Tree] = None) -&gt; npt.NDArray[np.float64]:\n        \"\"\"\n        Calculate fitness values for the given trees.\n\n        Args:\n            trees: List of trees to evaluate. If None, uses the current population.\n\n        Returns:\n            NumPy array of fitness values\n        \"\"\"\n        if trees is None:\n            trees = self.population\n        logger.debug(f\"Calculating fitness for {len(trees)} trees\")\n        fitnesses = np.zeros(shape=(len(trees), len(self.objective_functions)))\n        for ix, objective_function in enumerate(self.objective_functions):\n            fitnesses[:, ix] = np.array([objective_function(tree, self.gt_tensor) for tree in trees])\n        return fitnesses\n\n    def run_iteration(self):\n        \"\"\"\n        Run a single iteration of the evolutionary algorithm.\n\n        This method:\n        1. Calculates fitness values for the current population\n        2. Performs tournament selection and crossover to create new trees\n        3. Applies mutations to some of the new trees\n        4. Removes duplicate trees from the population\n        \"\"\"\n        logger.info(\"Starting evolution iteration\")\n        if self.fitnesses is None:\n            self.fitnesses = self._calculate_fitnesses(self.population).round(\n                3\n            )  # this generally unnecessarily happens again &gt; probably not with the if\n\n        logger.debug(\"Performing tournament selection and crossover\")\n        assert self.fitnesses.shape[0] == len(self.population)\n        crossover_count = self._perform_crossovers(self.fitnesses)\n        assert self.fitnesses.shape[0] == len(self.population)\n        logger.debug(f\"Performed {crossover_count} crossover operations\")\n\n        logger.debug(\"Applying mutations\")\n        mutation_count = self._mutate_additional_population()\n        assert self.fitnesses.shape[0] == len(self.population)\n        logger.info(f\"Applied {mutation_count} mutations\")\n\n        joined_population = np.array(self.population + self.additional_population)  # maybe worth it to calculated fitnesses first?\n        codes = np.array([tree.__repr__() for tree in joined_population])\n        mask = first_uniques_mask(codes)\n        self.population = list(joined_population[mask])\n        self.fitnesses = self._calculate_fitnesses(self.population).round(3)\n        assert self.fitnesses.shape[0] == len(self.population)\n\n        logger.debug(f\"Removed {len(joined_population) - sum(mask)} duplicate trees\")\n        logger.debug(f\"New population size: {len(self.population)}\")\n\n        self.population, self.fitnesses = choose_pareto_then_proximity(\n            self.population, self.fitnesses, self.objectives, self.population_size, self.minimize_node_count\n        )\n\n        assert self.fitnesses.shape[0] == len(self.population)\n\n        self.additional_population = []\n\n    def _perform_crossovers(self, fitnesses: npt.NDArray[np.float64]):\n        crossover_count = 0\n        while len(self.additional_population) &lt; (self.population_multiplier * self.population_size):\n            idx1, idx2 = tournament_selection_indexes(fitnesses, self.tournament_size, self.optimal_point)\n            parent_1, parent_2 = self.population[idx1], self.population[idx2]\n            new_tree_1, new_tree_2 = crossover(parent_1, parent_2)\n            self.additional_population += [new_tree_1, new_tree_2]\n            crossover_count += 1\n        return crossover_count\n\n    def _mutate_additional_population(self) -&gt; int:\n        mutation_count = 0\n        for tree in self.additional_population:\n            mutation_chance = np.random.rand()\n            if mutation_chance &lt; tree.mutation_chance:\n                allowed_mutations = np.array(get_allowed_mutations(tree))\n                chosen_mutation = np.random.choice(allowed_mutations)\n                logger.trace(f\"Applying mutation: {chosen_mutation.__name__}\")\n                mutated_tree = chosen_mutation(\n                    tree,\n                    models=self.models,\n                    ids=self.ids,\n                    allowed_ops=self.allowed_ops,\n                )\n                self.additional_population.append(mutated_tree)\n                mutation_count += 1\n        return mutation_count\n\n    def train(self, iterations: int):\n        \"\"\"\n        Run the evolutionary algorithm for a specified number of iterations.\n\n        Args:\n            iterations: Number of evolution iterations to run\n        \"\"\"\n        logger.info(f\"Starting evolution with {iterations} iterations\")\n        self._call_hook(\"on_evolution_start\")\n\n        for i in tqdm.tqdm(range(iterations)):\n            logger.info(f\"Generation {i + 1}/{iterations}\")\n            self._call_hook(\"on_generation_start\")  # possibly move to run_iteration instead\n            self.run_iteration()\n            self._call_hook(\"on_generation_end\")\n\n            if self.should_stop:\n                logger.info(\"Early stopping triggered\")\n                break\n\n        logger.info(\"Evolution complete\")\n        self._call_hook(\"on_evolution_end\")\n\n    def _build_train_tensors(self, preds_source, gt_path):\n        \"\"\"\n        Load prediction tensors and ground truth from files.\n\n        Args:\n            preds_source: Source of model predictions (path or iterable of paths)\n            gt_path: Path to ground truth data\n\n        Returns:\n            Tuple of (train_tensors dictionary, ground truth tensor)\n        \"\"\"\n        logger.info(\"Loading prediction tensors and ground truth\")\n        tensor_paths = []\n        if isinstance(preds_source, str):\n            preds_source = Path(preds_source)\n        if isinstance(preds_source, Path):\n            logger.debug(f\"Scanning directory for tensors: {preds_source}\")\n            tensor_paths = list(preds_source.glob(\"*\"))\n        elif hasattr(preds_source, \"__iter__\"):\n            marked_paths, all_same = mark_paths(preds_source)\n            if all_same:\n                if marked_paths[0] == \"dir\":\n                    for pred_source in preds_source:\n                        pred_source = Path(pred_source)\n                        tensor_paths += list(pred_source.glob(\"*\"))\n                elif marked_paths[0] == \"file\":\n                    tensor_paths = list(preds_source)\n            else:\n                raise ValueError(\n                    \"preds source must be either path to directory with predictions,\"\n                    \" list of paths to directories with predictions, or list of paths to predictions\"\n                )\n\n        train_tensors = {}\n        for tensor_path in tensor_paths:\n            logger.debug(f\"Loading tensor: {tensor_path}\")\n            tensor_id = Path(tensor_path).name\n            if tensor_id not in train_tensors:\n                train_tensors[tensor_id] = B.load(tensor_path, device=DEVICE)\n            else:\n                train_tensors[tensor_id] = B.concat([train_tensors[tensor_id], B.load(tensor_path, device=DEVICE)])\n\n        logger.debug(f\"Loaded {len(train_tensors)} prediction tensors\")\n        logger.debug(f\"Loading ground truth from: {gt_path}\")\n\n        gt_tensor: None | Tensor = None\n        if isinstance(gt_path, str):\n            gt_path = Path(gt_path)\n        if isinstance(gt_path, Path):\n            if os.path.isdir(gt_path):\n                for path in gt_path.glob(\"*\"):\n                    if gt_tensor is None:\n                        gt_tensor = B.load(path, device=DEVICE)\n                    else:\n                        gt_tensor = B.concat([gt_tensor, B.load(path, device=DEVICE)])  # type: ignore\n            else:\n                gt_tensor = B.load(gt_path, device=DEVICE)\n        elif hasattr(gt_path, \"__iter__\"):\n            for path in gt_path:\n                if gt_tensor is None:\n                    gt_tensor = B.load(path, device=DEVICE)\n                else:\n                    gt_tensor = B.concat([gt_tensor, B.load(path, device=DEVICE)])  # type: ignore\n        else:\n            raise ValueError(f\"{gt_path} is not valid for loading gt\")\n\n        logger.info(\"Tensors loaded successfully\")\n        return train_tensors, gt_tensor\n\n    def _validate_input(self, fix_swapped=True):  # no way to change this argument for now TODO\n        \"\"\"\n        Validate that all input tensors have compatible shapes.\n\n        Checks if all prediction tensors have the same shape and if the ground truth\n        tensor has a compatible shape. Can optionally fix swapped dimensions in the\n        ground truth tensor.\n\n        Args:\n            fix_swapped: If True, attempts to fix swapped dimensions in ground truth tensor\n\n        Raises:\n            ValueError: If tensor shapes are incompatible and cannot be fixed\n        \"\"\"\n        logger.info(\"Validating input tensors\")\n        # check if all tensors have the same shape\n        shapes = [B.shape(tensor) for tensor in self.train_tensors.values()]\n\n        if len(set(shapes)) &gt; 1:\n            logger.error(f\"Tensors have different shapes: {shapes}\")\n            raise ValueError(f\"Tensors have different shapes: {shapes}\")\n\n        logger.debug(f\"All prediction tensors have shape: {shapes[0]}\")\n        logger.debug(f\"Ground truth tensor has shape: {B.shape(self.gt_tensor)}\")\n\n        if B.shape(self.gt_tensor) != shapes[0]:\n            gt_shape = B.shape(self.gt_tensor)\n            if len(shapes[0]) &gt; 1 and (len(gt_shape) == 1 or gt_shape[-1] == 1):\n                pass\n            elif fix_swapped:\n                if (shapes[0] == B.shape(self.gt_tensor)[::-1]) and (len(shapes[0]) == 2):\n                    logger.warning(f\"Ground truth tensor dimensions appear to be swapped. Reshaping from {B.shape(self.gt_tensor)} to {shapes[0]}\")\n                    self.gt_tensor = B.reshape(self.gt_tensor, shapes[0])\n                    logger.info(\"Tensor shapes fixed successfully\")\n                else:\n                    logger.error(f\"Ground truth tensor shape {B.shape(self.gt_tensor)} incompatible with prediction tensor shape {shapes[0]}\")\n                    raise ValueError(f\"Ground truth tensor has incompatible shape: {B.shape(self.gt_tensor)} vs {shapes[0]}\")\n            else:\n                logger.error(f\"Ground truth tensor shape {B.shape(self.gt_tensor)} does not match prediction tensor shape {shapes[0]}\")\n                raise ValueError(f\"Ground truth tensor has different shape than input tensors: {shapes[0]} != {B.shape(self.gt_tensor)}\")\n\n        logger.info(\"Input validation successful\")\n\n    @property\n    def pareto_trees(self) -&gt; List[Tree]:\n        assert isinstance(self.fitnesses, np.ndarray), \"Fitnesses not yet initialized. Did you run any iteration?\"\n        all_pareto_trees, _ = choose_pareto(self.population, self.fitnesses, len(self.population), self.objectives, self.minimize_node_count)\n        return all_pareto_trees\n\n    @property\n    def pareto_fitnesses(self) -&gt; np.ndarray:\n        assert isinstance(self.fitnesses, np.ndarray), \"Fitnesses not yet initialized. Did you run any iteration?\"\n        _, pareto_fitnesses = choose_pareto(self.population, self.fitnesses, len(self.population), self.objectives, self.minimize_node_count)\n        return pareto_fitnesses\n</code></pre>"},{"location":"api/core/#okapi.okapi.Okapi.__init__","title":"<code>__init__(preds_source, gt_path, population_size, population_multiplier, tournament_size, minimize_node_count=True, objective_functions=(average_precision_fitness,), objectives=(maximize,), allowed_ops=(MEAN, MIN, MAX, WEIGHTED_MEAN, FAR_THRESHOLD, CLOSE_THRESHOLD), callbacks=tuple(), backend=None, seed=0, postprocessing_function=None)</code>","text":"<p>Initialize the Okapi evolutionary algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>preds_source</code> <code>Union[Path, str, Iterable[Path], Iterable[str]]</code> <p>Source of model predictions, can be a path to directory or iterable of paths</p> required <code>gt_path</code> <code>Union[Path, str, Iterable[Path], Iterable[str]]</code> <p>Path to ground truth data, can be a single path or iterable of paths. Should match preds_source by order</p> required <code>population_size</code> <code>int</code> <p>Size of the population to evolve</p> required <code>population_multiplier</code> <code>int</code> <p>Factor determining how many additional trees to generate</p> required <code>tournament_size</code> <code>int</code> <p>Number of trees to consider in tournament selection</p> required <code>minimize_node_count</code> <code>bool</code> <p>Whether the pareto frontier models should also consider node count.</p> <code>True</code> <code>objective_functions</code> <code>Sequence[Callable[[Tree, Tensor], float]]</code> <p>Functions that calculate the fitnesses that are to be optimized</p> <code>(average_precision_fitness,)</code> <code>objectives</code> <code>Sequence[Callable[[float, float], bool]]</code> <p>Functions that copare two fitnesses and return True if first is better than second. Usually maximize or minimize</p> <code>(maximize,)</code> <code>allowed_ops</code> <code>Sequence[Type[OperatorNode]]</code> <p>Sequence of operator node types that can be used in trees</p> <code>(MEAN, MIN, MAX, WEIGHTED_MEAN, FAR_THRESHOLD, CLOSE_THRESHOLD)</code> <code>callbacks</code> <code>Iterable[Callback]</code> <p>Iterable of callback objects for monitoring/modifying evolution</p> <code>tuple()</code> <code>backend</code> <code>Union[str, None]</code> <p>Optional backend implementation for tensor operations</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility</p> <code>0</code> <code>postprocessing_function</code> <p>Function applied after each Op Node.</p> <code>None</code> Source code in <code>okapi/okapi.py</code> <pre><code>def __init__(\n    self,\n    preds_source: Union[Path, str, Iterable[Path], Iterable[str]],\n    gt_path: Union[Path, str, Iterable[Path], Iterable[str]],\n    population_size: int,\n    population_multiplier: int,\n    tournament_size: int,\n    minimize_node_count: bool = True,\n    objective_functions: Sequence[Callable[[Tree, lib_types.Tensor], float]] = (average_precision_fitness,),\n    objectives: Sequence[Callable[[float, float], bool]] = (maximize,),\n    allowed_ops: Sequence[Type[OperatorNode]] = (MEAN, MIN, MAX, WEIGHTED_MEAN, FAR_THRESHOLD, CLOSE_THRESHOLD),\n    callbacks: Iterable[Callback] = tuple(),\n    backend: Union[str, None] = None,\n    seed: int = 0,\n    postprocessing_function=None,\n):\n    \"\"\"\n    Initialize the Okapi evolutionary algorithm.\n\n    Args:\n        preds_source: Source of model predictions, can be a path to directory or iterable of paths\n        gt_path: Path to ground truth data, can be a single path or iterable of paths. Should match preds_source by order\n        population_size: Size of the population to evolve\n        population_multiplier: Factor determining how many additional trees to generate\n        tournament_size: Number of trees to consider in tournament selection\n        minimize_node_count: Whether the pareto frontier models should also consider node count.\n        objective_functions: Functions that calculate the fitnesses that are to be optimized\n        objectives: Functions that copare two fitnesses and return True if first is better than second. Usually maximize or minimize\n        allowed_ops: Sequence of operator node types that can be used in trees\n        callbacks: Iterable of callback objects for monitoring/modifying evolution\n        backend: Optional backend implementation for tensor operations\n        seed: Random seed for reproducibility\n        postprocessing_function: Function applied after each Op Node.\n        Most of the operations may break some data characteristics, for example vector summing to one. This can be used to fix that.\n    \"\"\"\n    # Validate parameters\n    if population_size &lt;= 0:\n        raise ValueError(f\"population_size must be positive, got {population_size}\")\n    if population_multiplier &lt;= 0:\n        raise ValueError(f\"population_multiplier must be positive, got {population_multiplier}\")\n    if tournament_size &lt;= 0:\n        raise ValueError(f\"tournament_size must be positive, got {tournament_size}\")\n    if tournament_size &gt; population_size:\n        raise ValueError(\n            f\"tournament_size ({tournament_size}) cannot be larger than population_size ({population_size})\"\n        )\n\n    if backend is not None:\n        Backend.set_backend(backend)\n    if seed is not None:\n        np.random.seed(seed)\n    if postprocessing_function:\n        set_postprocessing_function(postprocessing_function)\n\n    self.population_size = population_size\n    self.population_multiplier = population_multiplier\n    self.tournament_size = tournament_size\n    self.minimize_node_count = minimize_node_count\n    self.seed = seed\n\n    self.objective_functions = objective_functions\n    self.objectives = objectives\n    assert len(objectives) == len(objective_functions), \"The number of (optimization) objectives and objective functions is not the same\"\n    self.optimal_point = _get_optimal_point_based_on_list_of_objective_functions(self.objectives)\n\n    self.callbacks = callbacks\n    self.allowed_ops = allowed_ops\n\n    self.train_tensors, self.gt_tensor = self._build_train_tensors(preds_source, gt_path)\n    self.ids, self.models = list(self.train_tensors.keys()), list(self.train_tensors.values())\n    self._validate_input()\n\n    # state\n    self.should_stop = False\n\n    self.population = self._initialize_population()\n    self.additional_population: List[Tree] = []  # for potential callbacks\n    self.fitnesses: None | npt.NDArray[np.float64] = None\n</code></pre>"},{"location":"api/core/#okapi.okapi.Okapi.run_iteration","title":"<code>run_iteration()</code>","text":"<p>Run a single iteration of the evolutionary algorithm.</p> <p>This method: 1. Calculates fitness values for the current population 2. Performs tournament selection and crossover to create new trees 3. Applies mutations to some of the new trees 4. Removes duplicate trees from the population</p> Source code in <code>okapi/okapi.py</code> <pre><code>def run_iteration(self):\n    \"\"\"\n    Run a single iteration of the evolutionary algorithm.\n\n    This method:\n    1. Calculates fitness values for the current population\n    2. Performs tournament selection and crossover to create new trees\n    3. Applies mutations to some of the new trees\n    4. Removes duplicate trees from the population\n    \"\"\"\n    logger.info(\"Starting evolution iteration\")\n    if self.fitnesses is None:\n        self.fitnesses = self._calculate_fitnesses(self.population).round(\n            3\n        )  # this generally unnecessarily happens again &gt; probably not with the if\n\n    logger.debug(\"Performing tournament selection and crossover\")\n    assert self.fitnesses.shape[0] == len(self.population)\n    crossover_count = self._perform_crossovers(self.fitnesses)\n    assert self.fitnesses.shape[0] == len(self.population)\n    logger.debug(f\"Performed {crossover_count} crossover operations\")\n\n    logger.debug(\"Applying mutations\")\n    mutation_count = self._mutate_additional_population()\n    assert self.fitnesses.shape[0] == len(self.population)\n    logger.info(f\"Applied {mutation_count} mutations\")\n\n    joined_population = np.array(self.population + self.additional_population)  # maybe worth it to calculated fitnesses first?\n    codes = np.array([tree.__repr__() for tree in joined_population])\n    mask = first_uniques_mask(codes)\n    self.population = list(joined_population[mask])\n    self.fitnesses = self._calculate_fitnesses(self.population).round(3)\n    assert self.fitnesses.shape[0] == len(self.population)\n\n    logger.debug(f\"Removed {len(joined_population) - sum(mask)} duplicate trees\")\n    logger.debug(f\"New population size: {len(self.population)}\")\n\n    self.population, self.fitnesses = choose_pareto_then_proximity(\n        self.population, self.fitnesses, self.objectives, self.population_size, self.minimize_node_count\n    )\n\n    assert self.fitnesses.shape[0] == len(self.population)\n\n    self.additional_population = []\n</code></pre>"},{"location":"api/core/#okapi.okapi.Okapi.train","title":"<code>train(iterations)</code>","text":"<p>Run the evolutionary algorithm for a specified number of iterations.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>int</code> <p>Number of evolution iterations to run</p> required Source code in <code>okapi/okapi.py</code> <pre><code>def train(self, iterations: int):\n    \"\"\"\n    Run the evolutionary algorithm for a specified number of iterations.\n\n    Args:\n        iterations: Number of evolution iterations to run\n    \"\"\"\n    logger.info(f\"Starting evolution with {iterations} iterations\")\n    self._call_hook(\"on_evolution_start\")\n\n    for i in tqdm.tqdm(range(iterations)):\n        logger.info(f\"Generation {i + 1}/{iterations}\")\n        self._call_hook(\"on_generation_start\")  # possibly move to run_iteration instead\n        self.run_iteration()\n        self._call_hook(\"on_generation_end\")\n\n        if self.should_stop:\n            logger.info(\"Early stopping triggered\")\n            break\n\n    logger.info(\"Evolution complete\")\n    self._call_hook(\"on_evolution_end\")\n</code></pre>"},{"location":"api/core/#tree-class","title":"Tree Class","text":"<p>The <code>Tree</code> class represents a computational tree structure for model ensemble composition.</p> <pre><code>from okapi.tree import Tree\n</code></pre> <p>Represents a computational tree structure for model ensemble composition.</p> <p>The Tree class is a central component in OKAPI, representing a hierarchical structure of nodes that define how different models are combined. Each tree has a ValueNode as its root, and may contain multiple ValueNodes and OperatorNodes arranged in a tree structure.</p> <p>ValueNodes contain tensor data (model predictions), while OperatorNodes define operations to combine these predictions (such as mean, min, max, weighted mean). The tree's evaluation produces a combined prediction by recursively applying these operations.</p> <p>Trees can be manipulated through various operations like pruning, appending, and replacing nodes, making them suitable for evolutionary algorithms where trees evolve over generations.</p> <p>Attributes:</p> Name Type Description <code>root</code> <p>The root node of the tree (must be a ValueNode)</p> <code>nodes</code> <code>dict[str, list]</code> <p>Dictionary containing lists of all value nodes and operator nodes in the tree</p> <code>mutation_chance</code> <p>Probability of mutation for this tree during evolution</p> Source code in <code>okapi/tree.py</code> <pre><code>class Tree:\n    \"\"\"\n    Represents a computational tree structure for model ensemble composition.\n\n    The Tree class is a central component in OKAPI, representing a hierarchical structure\n    of nodes that define how different models are combined. Each tree has a ValueNode as its root,\n    and may contain multiple ValueNodes and OperatorNodes arranged in a tree structure.\n\n    ValueNodes contain tensor data (model predictions), while OperatorNodes define operations\n    to combine these predictions (such as mean, min, max, weighted mean). The tree's evaluation\n    produces a combined prediction by recursively applying these operations.\n\n    Trees can be manipulated through various operations like pruning, appending, and replacing\n    nodes, making them suitable for evolutionary algorithms where trees evolve over generations.\n\n    Attributes:\n        root: The root node of the tree (must be a ValueNode)\n        nodes: Dictionary containing lists of all value nodes and operator nodes in the tree\n        mutation_chance: Probability of mutation for this tree during evolution\n    \"\"\"\n\n    def __init__(self, root: ValueNode, mutation_chance=0.1):\n        self.root = root\n        logger.debug(f\"Creating new tree with root: {root}\")\n\n        if isinstance(self.root, OperatorNode):\n            logger.error(\"Cannot initialize tree with OperatorNode as root\")\n            raise Exception(\"Cannot get evaluation of tree with OpNode as root\")\n\n        self.nodes: dict[str, list] = {\"value_nodes\": [], \"op_nodes\": []}\n        self.mutation_chance = mutation_chance\n        self.update_nodes()\n        logger.trace(f\"Tree initialized with {len(self.nodes['value_nodes'])} value nodes and {len(self.nodes['op_nodes'])} operator nodes\")\n\n    def update_nodes(self):\n        \"\"\"\n        Update the internal collections of nodes in the tree.\n\n        This method traverses the tree and categorizes all nodes into value nodes and operator nodes,\n        updating the internal `nodes` dictionary.\n        \"\"\"\n        logger.debug(\"Updating tree node collections\")\n        self.nodes = {\"value_nodes\": [], \"op_nodes\": []}\n        root_nodes = self.root.get_nodes()\n        for node in root_nodes:\n            if isinstance(node, ValueNode):\n                self.nodes[\"value_nodes\"].append(node)\n            else:\n                self.nodes[\"op_nodes\"].append(node)\n        logger.trace(f\"Updated nodes: {len(self.nodes['value_nodes'])} value nodes, {len(self.nodes['op_nodes'])} operator nodes\")\n\n    @staticmethod\n    def create_tree_from_root(root: ValueNode, mutation_chance=0.1):\n        \"\"\"\n        Create a new tree with the given root node.\n\n        Args:\n            root: The ValueNode to use as the root of the new tree\n            mutation_chance: Probability of mutation for the new tree\n\n        Returns:\n            A new Tree instance\n        \"\"\"\n        logger.debug(f\"Creating tree from root node with mutation chance: {mutation_chance}\")\n        tree = Tree(root, mutation_chance)\n        return tree\n\n    @property\n    def evaluation(self):\n        \"\"\"\n        Calculate and return the evaluation of the tree.\n\n        The evaluation is the result of recursively applying all operations\n        in the tree, starting from the root node.\n\n        Returns:\n            The tensor resulting from evaluating the tree\n        \"\"\"\n        # WARNING: This may not make sense for cases other than binary classification (Squeezing)\n        # return B.squeeze(self.root.evaluation if self.root.evaluation is not None else self.root.calculate())\n        return self.root.evaluation if self.root.evaluation is not None else self.root.calculate()\n\n    @property\n    def nodes_count(self):\n        \"\"\"\n        Count the total number of nodes in the tree.\n\n        Returns:\n            The sum of value nodes and operator nodes\n        \"\"\"\n        return len(self.nodes[\"value_nodes\"]) + len(self.nodes[\"op_nodes\"])\n\n    def _clean_evals(self):\n        \"\"\"\n        Reset the cached evaluation results for all value nodes in the tree.\n\n        This forces recalculation of node evaluations when the tree structure changes.\n        \"\"\"\n        logger.debug(\"Clearing cached evaluations for all value nodes\")\n        for node in self.nodes[\"value_nodes\"]:\n            node.evaluation = None\n\n    def _clean_values_and_evals(self):\n        for value_node in self.nodes[\"value_nodes\"]:\n            value_node.value = value_node.evaluation = None\n\n    def recalculate(self):\n        \"\"\"\n        Force recalculation of the tree evaluation.\n\n        This method clears any cached evaluations and triggers a fresh calculation.\n        It also updates the nodes dictionary\n\n        Returns:\n            The newly calculated evaluation of the tree\n        \"\"\"\n        logger.debug(\"Recalculating tree evaluation\")\n        self._clean_evals()\n        self.update_nodes()\n        evaluation = self.evaluation\n        logger.trace(\"Tree recalculation complete\")\n        return evaluation\n\n    def copy(self):\n        \"\"\"\n        Create a deep copy of the tree.\n\n        Returns:\n            A new Tree instance that is a deep copy of the current tree\n        \"\"\"\n        logger.debug(\"Creating deep copy of tree\")\n        root_copy: ValueNode = cast(ValueNode, self.root.copy_subtree())\n        return Tree.create_tree_from_root(root_copy)\n\n    def prune_at(self, node: Node) -&gt; Node:\n        \"\"\"\n        Remove a node and its subtree from the tree.\n\n        This method removes the specified node and all its descendants from the tree.\n        If the node is the only child of an operator node, that operator node will\n        also be pruned.\n\n        Args:\n            node: The node to prune from the tree\n\n        Returns:\n            The pruned node (which is no longer part of the tree). If parent was pruned, the parent will be returned.\n\n        Raises:\n            ValueError: If the node is not found in the tree or if attempting to prune the root node\n        \"\"\"\n        logger.debug(f\"Pruning node from tree: {node}\")\n\n        if node not in self.nodes[\"value_nodes\"] and node not in self.nodes[\"op_nodes\"]:\n            logger.error(f\"Attempted to prune node not in tree: {node}\")\n            raise ValueError(\"Node not found in tree\")\n\n        if node.parent is None:\n            logger.error(\"Cannot prune root node\")\n            raise ValueError(\"Cannot prune root node\")\n\n        if isinstance(node.parent, OperatorNode) and (\n            len(node.parent.children) &lt; 2\n        ):  # if only child of op node is to be pruned, remove the parent instead\n            logger.debug(f\"Node is the only child of operator node, pruning parent: {node.parent}\")\n            return self.prune_at(node.parent)\n\n        subtree_nodes = node.get_nodes()\n        node_count = len(subtree_nodes)\n\n        logger.debug(f\"Removing {node_count} nodes in subtree\")\n        for subtree_node in subtree_nodes:\n            if isinstance(subtree_node, ValueNode):\n                self.nodes[\"value_nodes\"].remove(subtree_node)\n            else:\n                self.nodes[\"op_nodes\"].remove(subtree_node)\n\n        node.parent.remove_child(node)\n        logger.debug(\"Pruning complete, clearing cached evaluations\")\n        self._clean_evals()\n        return node\n\n    def append_after(self, node: Node, new_node: Node):\n        \"\"\"\n        Append a new node as a child of an existing node.\n\n        The new node must be of a different type than the existing node\n        (i.e., value nodes can only append operator nodes and vice versa).\n\n        Args:\n            node: The existing node to which the new node will be appended\n            new_node: The new node to append\n\n        Raises:\n            ValueError: If the node is not found in the tree or if attempting to append\n                       a node of the same type\n        \"\"\"\n        logger.debug(f\"Appending node {new_node} after {node}\")\n\n        if node not in self.nodes[\"value_nodes\"] and node not in self.nodes[\"op_nodes\"]:\n            logger.error(f\"Attempted to append to node not in tree: {node}\")\n            raise ValueError(\"Node not found in tree\")\n\n        if check_if_both_types_same_node_variant(type(node), type(new_node)):\n            logger.error(f\"Cannot append node of same type: {type(node).__name__} and {type(new_node).__name__}\")\n            raise ValueError(\"Cannot append node of the same type\")\n\n        subtree_nodes = new_node.get_nodes()\n        logger.debug(f\"Adding {len(subtree_nodes)} nodes from subtree\")\n\n        for subtree_node in subtree_nodes:\n            if isinstance(subtree_node, ValueNode):\n                self.nodes[\"value_nodes\"].append(subtree_node)\n            else:\n                self.nodes[\"op_nodes\"].append(subtree_node)\n\n        node.add_child(new_node)\n        logger.debug(\"Append complete, clearing cached evaluations\")\n        self._clean_evals()\n\n    def replace_at(self, at: Node, replacement: Node) -&gt; Self:\n        \"\"\"\n        Replace a node in the tree with another node.\n\n        The replacement node must be of the same type as the node being replaced.\n        This operation preserves the parent-child relationships.\n\n        Args:\n            at: The node to be replaced\n            replacement: The new node that will replace the existing node\n\n        Returns:\n            Self reference to allow method chaining\n\n        Raises:\n            AssertionError: If the replacement node is not of the same type as the node being replaced\n        \"\"\"\n        assert (isinstance(replacement, ValueNode) and isinstance(at, ValueNode)) or (\n            isinstance(replacement, OperatorNode) and isinstance(at, OperatorNode)\n        ), \"Replacement node must be of the same parent type (ValueNode or OperatorNode) as the node being replaced\"\n        at_parent = at.parent\n\n        if at_parent is None:\n            assert isinstance(self.root, ValueNode), \"Root must be a value node\"\n            assert isinstance(replacement, ValueNode), \"Replacement for root must be a value node\"\n            logger.warning(\"Node at replacement is root node\")\n            self.root = replacement\n        else:\n            at_parent.replace_child(at, replacement)\n\n        if isinstance(at, ValueNode):\n            self.nodes[\"value_nodes\"].remove(at)\n            self.nodes[\"value_nodes\"].append(replacement)\n        else:\n            self.nodes[\"op_nodes\"].remove(at)\n            self.nodes[\"op_nodes\"].append(replacement)\n\n        self._clean_evals()\n        return self\n\n    def get_random_node(self, nodes_type: str | None = None, allow_root=True, allow_leaves=True):\n        \"\"\"\n        Get a random node from the tree based on specified constraints.\n\n        Args:\n            nodes_type: Optional type of nodes to consider ('value_nodes' or 'op_nodes')\n                       If None, a random type will be chosen\n            allow_root: Whether to allow selecting the root node\n            allow_leaves: Whether to allow selecting leaf nodes\n\n        Returns:\n            A randomly selected node that satisfies the constraints\n\n        Raises:\n            ValueError: If no node satisfying the constraints is found\n        \"\"\"\n        if self.root.children == []:\n            if allow_root:\n                if nodes_type is None or nodes_type == \"value_nodes\":\n                    return self.root\n                else:\n                    raise ValueError(\"Tree has only root node and nodes_type is not value_nodes\")\n            else:\n                raise ValueError(\"Tree has only root node and allow_root is set to False\")\n\n        if nodes_type is not None:\n            assert nodes_type in (\"value_nodes\", \"op_nodes\"), f'Unsupported node type \"{nodes_type}\" selected.'\n            nodes_types = [\n                nodes_type,\n            ]\n        else:\n            nodes_types = list(np.random.permutation([\"op_nodes\", \"value_nodes\"]))\n\n        for nodes_type in nodes_types:\n            assert nodes_type is not None, \"Nodes type cannot be None\"\n            order = np.arange(len(self.nodes[nodes_type]))\n            for i in order:\n                node = self.nodes[nodes_type][i]\n                if (allow_leaves or node.children != []) and (allow_root or node != self.root):\n                    return node\n        raise ValueError(\"No node found that complies to the constraints\")\n\n    @property\n    def unique_value_node_ids(self):\n        \"\"\"\n        Get the unique IDs of all value nodes in the tree.\n\n        Returns:\n            A list of unique IDs from all value nodes\n        \"\"\"\n        return list(set([node.id for node in self.nodes[\"value_nodes\"]]))\n\n    @property\n    def value_nodes(self):\n        return self.nodes[\"value_nodes\"]\n\n    @property\n    def op_nodes(self):\n        return self.nodes[\"op_nodes\"]\n\n    def save_tree_architecture(self, output_path):  # TODO: needs adjustment for weighted node\n        \"\"\"\n        Save the tree's architecture to a file.\n\n        This method creates a copy of the tree with tensor values removed\n        and saves it to the specified path using pickle serialization.\n\n        Args:\n            output_path: Path where the tree architecture will be saved\n        \"\"\"\n        logger.info(f\"Saving tree architecture to {output_path}\")\n        copy_tree = self.copy()\n        copy_tree._clean_values_and_evals()\n\n        Pickle.save(output_path, copy_tree)\n        logger.debug(\"Tree architecture saved successfully\")\n\n    @staticmethod\n    def load_tree_architecture(architecture_path) -&gt; \"Tree\":  # TODO: needs adjusted for weighted node\n        \"\"\"\n        Load a tree architecture from a file.\n\n        Args:\n            architecture_path: Path to the saved tree architecture file\n\n        Returns:\n            The loaded Tree object without tensor values\n        \"\"\"\n        logger.info(f\"Loading tree architecture from {architecture_path}\")\n        tree = Pickle.load(architecture_path)\n        logger.debug(\"Tree architecture loaded successfully\")\n        return tree\n\n    def _load_tensors_from_path(self, preds_directory):\n        current_tensors = {}\n        preds_directory = Path(preds_directory)\n        for value_node in self.nodes[\"value_nodes\"]:\n            node_id = value_node.id\n            if node_id not in current_tensors:\n                logger.debug(f\"Loading tensor for node ID: {node_id}\")\n                current_tensors[node_id] = B.load(preds_directory / str(node_id), DEVICE)\n            else:\n                logger.trace(f\"Using pre-loaded tensor for node ID: {node_id}\")\n        return current_tensors\n\n    def _load_tensors_to_tree(self, preds_directory, current_tensors):\n        if preds_directory is not None:\n            preds_directory = Path(preds_directory)\n            loaded_tensors = self._load_tensors_from_path(preds_directory)\n            current_tensors.update(loaded_tensors)\n        for value_node in self.nodes[\"value_nodes\"]:\n            node_id = value_node.id\n            value_node.value = current_tensors[node_id]\n        return current_tensors\n\n    def do_pred_on_another_tensors(\n        self, preds_directory: None | str | Path = None, current_tensors: None | dict = None, return_tree=False\n    ) -&gt; tuple[None | Tensor, \"Tree\"] | Tensor:\n        assert not all(\n            [current_tensors is not None, preds_directory is not None]\n        ), \"Either preds directory or current tensors needs to be set, not both\"\n        assert any(\n            [current_tensors is not None, preds_directory is not None]\n        ), \"Either preds directory or current tensors needs to be set, none was set\"\n\n        current_tensors = {}\n        copy_tree = self.copy()\n        copy_tree._clean_values_and_evals()\n        current_tensors = copy_tree._load_tensors_to_tree(preds_directory, current_tensors)\n        if return_tree:\n            return copy_tree.evaluation, copy_tree\n\n        return copy_tree.evaluation\n\n    @staticmethod\n    def load_tree(architecture_path, preds_directory, tensors=None) -&gt; Tuple[\"Tree\", dict]:\n        \"\"\"\n        Load a complete tree with tensor values from files.\n\n        This method loads a tree architecture and then loads the associated tensor\n        values for each value node from the specified directory.\n\n        Args:\n            architecture_path: Path to the saved tree architecture file\n            preds_directory: Directory containing the tensor files\n            tensors: Optional dictionary of pre-loaded tensors\n\n        Returns:\n            A tuple containing:\n            - The loaded Tree object with tensor values\n            - A dictionary of all tensors used in the tree\n        \"\"\"\n        if tensors is None:\n            tensors = {}\n\n        logger.info(f\"Loading complete tree from {architecture_path} with tensors from {preds_directory}\")\n        logger.debug(f\"Starting with {len(tensors)} pre-loaded tensors\")\n\n        current_tensors = {}\n        current_tensors.update(tensors)  # tensors argument is mutable and we do not want to modify it\n\n        loaded = Tree.load_tree_architecture(architecture_path)\n        current_tensors = loaded._load_tensors_to_tree(preds_directory, current_tensors)\n\n        logger.info(\n            f\"Tree loaded successfully with {len(loaded.nodes['value_nodes'])} value nodes and {len(loaded.nodes['op_nodes'])} operator nodes\"\n        )\n        return loaded, current_tensors\n\n    def __repr__(self):\n        \"\"\"\n        Get a string representation of the tree.\n\n        Returns:\n            A string representation formed by concatenating the code of all nodes\n        \"\"\"\n        return \"_\".join(node.code for node in self.root.get_nodes())\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.evaluation","title":"<code>evaluation</code>  <code>property</code>","text":"<p>Calculate and return the evaluation of the tree.</p> <p>The evaluation is the result of recursively applying all operations in the tree, starting from the root node.</p> <p>Returns:</p> Type Description <p>The tensor resulting from evaluating the tree</p>"},{"location":"api/core/#okapi.tree.Tree.nodes_count","title":"<code>nodes_count</code>  <code>property</code>","text":"<p>Count the total number of nodes in the tree.</p> <p>Returns:</p> Type Description <p>The sum of value nodes and operator nodes</p>"},{"location":"api/core/#okapi.tree.Tree.unique_value_node_ids","title":"<code>unique_value_node_ids</code>  <code>property</code>","text":"<p>Get the unique IDs of all value nodes in the tree.</p> <p>Returns:</p> Type Description <p>A list of unique IDs from all value nodes</p>"},{"location":"api/core/#okapi.tree.Tree.__repr__","title":"<code>__repr__()</code>","text":"<p>Get a string representation of the tree.</p> <p>Returns:</p> Type Description <p>A string representation formed by concatenating the code of all nodes</p> Source code in <code>okapi/tree.py</code> <pre><code>def __repr__(self):\n    \"\"\"\n    Get a string representation of the tree.\n\n    Returns:\n        A string representation formed by concatenating the code of all nodes\n    \"\"\"\n    return \"_\".join(node.code for node in self.root.get_nodes())\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.append_after","title":"<code>append_after(node, new_node)</code>","text":"<p>Append a new node as a child of an existing node.</p> <p>The new node must be of a different type than the existing node (i.e., value nodes can only append operator nodes and vice versa).</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The existing node to which the new node will be appended</p> required <code>new_node</code> <code>Node</code> <p>The new node to append</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node is not found in the tree or if attempting to append        a node of the same type</p> Source code in <code>okapi/tree.py</code> <pre><code>def append_after(self, node: Node, new_node: Node):\n    \"\"\"\n    Append a new node as a child of an existing node.\n\n    The new node must be of a different type than the existing node\n    (i.e., value nodes can only append operator nodes and vice versa).\n\n    Args:\n        node: The existing node to which the new node will be appended\n        new_node: The new node to append\n\n    Raises:\n        ValueError: If the node is not found in the tree or if attempting to append\n                   a node of the same type\n    \"\"\"\n    logger.debug(f\"Appending node {new_node} after {node}\")\n\n    if node not in self.nodes[\"value_nodes\"] and node not in self.nodes[\"op_nodes\"]:\n        logger.error(f\"Attempted to append to node not in tree: {node}\")\n        raise ValueError(\"Node not found in tree\")\n\n    if check_if_both_types_same_node_variant(type(node), type(new_node)):\n        logger.error(f\"Cannot append node of same type: {type(node).__name__} and {type(new_node).__name__}\")\n        raise ValueError(\"Cannot append node of the same type\")\n\n    subtree_nodes = new_node.get_nodes()\n    logger.debug(f\"Adding {len(subtree_nodes)} nodes from subtree\")\n\n    for subtree_node in subtree_nodes:\n        if isinstance(subtree_node, ValueNode):\n            self.nodes[\"value_nodes\"].append(subtree_node)\n        else:\n            self.nodes[\"op_nodes\"].append(subtree_node)\n\n    node.add_child(new_node)\n    logger.debug(\"Append complete, clearing cached evaluations\")\n    self._clean_evals()\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.copy","title":"<code>copy()</code>","text":"<p>Create a deep copy of the tree.</p> <p>Returns:</p> Type Description <p>A new Tree instance that is a deep copy of the current tree</p> Source code in <code>okapi/tree.py</code> <pre><code>def copy(self):\n    \"\"\"\n    Create a deep copy of the tree.\n\n    Returns:\n        A new Tree instance that is a deep copy of the current tree\n    \"\"\"\n    logger.debug(\"Creating deep copy of tree\")\n    root_copy: ValueNode = cast(ValueNode, self.root.copy_subtree())\n    return Tree.create_tree_from_root(root_copy)\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.create_tree_from_root","title":"<code>create_tree_from_root(root, mutation_chance=0.1)</code>  <code>staticmethod</code>","text":"<p>Create a new tree with the given root node.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>ValueNode</code> <p>The ValueNode to use as the root of the new tree</p> required <code>mutation_chance</code> <p>Probability of mutation for the new tree</p> <code>0.1</code> <p>Returns:</p> Type Description <p>A new Tree instance</p> Source code in <code>okapi/tree.py</code> <pre><code>@staticmethod\ndef create_tree_from_root(root: ValueNode, mutation_chance=0.1):\n    \"\"\"\n    Create a new tree with the given root node.\n\n    Args:\n        root: The ValueNode to use as the root of the new tree\n        mutation_chance: Probability of mutation for the new tree\n\n    Returns:\n        A new Tree instance\n    \"\"\"\n    logger.debug(f\"Creating tree from root node with mutation chance: {mutation_chance}\")\n    tree = Tree(root, mutation_chance)\n    return tree\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.get_random_node","title":"<code>get_random_node(nodes_type=None, allow_root=True, allow_leaves=True)</code>","text":"<p>Get a random node from the tree based on specified constraints.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_type</code> <code>str | None</code> <p>Optional type of nodes to consider ('value_nodes' or 'op_nodes')        If None, a random type will be chosen</p> <code>None</code> <code>allow_root</code> <p>Whether to allow selecting the root node</p> <code>True</code> <code>allow_leaves</code> <p>Whether to allow selecting leaf nodes</p> <code>True</code> <p>Returns:</p> Type Description <p>A randomly selected node that satisfies the constraints</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no node satisfying the constraints is found</p> Source code in <code>okapi/tree.py</code> <pre><code>def get_random_node(self, nodes_type: str | None = None, allow_root=True, allow_leaves=True):\n    \"\"\"\n    Get a random node from the tree based on specified constraints.\n\n    Args:\n        nodes_type: Optional type of nodes to consider ('value_nodes' or 'op_nodes')\n                   If None, a random type will be chosen\n        allow_root: Whether to allow selecting the root node\n        allow_leaves: Whether to allow selecting leaf nodes\n\n    Returns:\n        A randomly selected node that satisfies the constraints\n\n    Raises:\n        ValueError: If no node satisfying the constraints is found\n    \"\"\"\n    if self.root.children == []:\n        if allow_root:\n            if nodes_type is None or nodes_type == \"value_nodes\":\n                return self.root\n            else:\n                raise ValueError(\"Tree has only root node and nodes_type is not value_nodes\")\n        else:\n            raise ValueError(\"Tree has only root node and allow_root is set to False\")\n\n    if nodes_type is not None:\n        assert nodes_type in (\"value_nodes\", \"op_nodes\"), f'Unsupported node type \"{nodes_type}\" selected.'\n        nodes_types = [\n            nodes_type,\n        ]\n    else:\n        nodes_types = list(np.random.permutation([\"op_nodes\", \"value_nodes\"]))\n\n    for nodes_type in nodes_types:\n        assert nodes_type is not None, \"Nodes type cannot be None\"\n        order = np.arange(len(self.nodes[nodes_type]))\n        for i in order:\n            node = self.nodes[nodes_type][i]\n            if (allow_leaves or node.children != []) and (allow_root or node != self.root):\n                return node\n    raise ValueError(\"No node found that complies to the constraints\")\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.load_tree","title":"<code>load_tree(architecture_path, preds_directory, tensors=None)</code>  <code>staticmethod</code>","text":"<p>Load a complete tree with tensor values from files.</p> <p>This method loads a tree architecture and then loads the associated tensor values for each value node from the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>architecture_path</code> <p>Path to the saved tree architecture file</p> required <code>preds_directory</code> <p>Directory containing the tensor files</p> required <code>tensors</code> <p>Optional dictionary of pre-loaded tensors</p> <code>None</code> <p>Returns:</p> Type Description <code>Tree</code> <p>A tuple containing:</p> <code>dict</code> <ul> <li>The loaded Tree object with tensor values</li> </ul> <code>Tuple[Tree, dict]</code> <ul> <li>A dictionary of all tensors used in the tree</li> </ul> Source code in <code>okapi/tree.py</code> <pre><code>@staticmethod\ndef load_tree(architecture_path, preds_directory, tensors=None) -&gt; Tuple[\"Tree\", dict]:\n    \"\"\"\n    Load a complete tree with tensor values from files.\n\n    This method loads a tree architecture and then loads the associated tensor\n    values for each value node from the specified directory.\n\n    Args:\n        architecture_path: Path to the saved tree architecture file\n        preds_directory: Directory containing the tensor files\n        tensors: Optional dictionary of pre-loaded tensors\n\n    Returns:\n        A tuple containing:\n        - The loaded Tree object with tensor values\n        - A dictionary of all tensors used in the tree\n    \"\"\"\n    if tensors is None:\n        tensors = {}\n\n    logger.info(f\"Loading complete tree from {architecture_path} with tensors from {preds_directory}\")\n    logger.debug(f\"Starting with {len(tensors)} pre-loaded tensors\")\n\n    current_tensors = {}\n    current_tensors.update(tensors)  # tensors argument is mutable and we do not want to modify it\n\n    loaded = Tree.load_tree_architecture(architecture_path)\n    current_tensors = loaded._load_tensors_to_tree(preds_directory, current_tensors)\n\n    logger.info(\n        f\"Tree loaded successfully with {len(loaded.nodes['value_nodes'])} value nodes and {len(loaded.nodes['op_nodes'])} operator nodes\"\n    )\n    return loaded, current_tensors\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.load_tree_architecture","title":"<code>load_tree_architecture(architecture_path)</code>  <code>staticmethod</code>","text":"<p>Load a tree architecture from a file.</p> <p>Parameters:</p> Name Type Description Default <code>architecture_path</code> <p>Path to the saved tree architecture file</p> required <p>Returns:</p> Type Description <code>Tree</code> <p>The loaded Tree object without tensor values</p> Source code in <code>okapi/tree.py</code> <pre><code>@staticmethod\ndef load_tree_architecture(architecture_path) -&gt; \"Tree\":  # TODO: needs adjusted for weighted node\n    \"\"\"\n    Load a tree architecture from a file.\n\n    Args:\n        architecture_path: Path to the saved tree architecture file\n\n    Returns:\n        The loaded Tree object without tensor values\n    \"\"\"\n    logger.info(f\"Loading tree architecture from {architecture_path}\")\n    tree = Pickle.load(architecture_path)\n    logger.debug(\"Tree architecture loaded successfully\")\n    return tree\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.prune_at","title":"<code>prune_at(node)</code>","text":"<p>Remove a node and its subtree from the tree.</p> <p>This method removes the specified node and all its descendants from the tree. If the node is the only child of an operator node, that operator node will also be pruned.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The node to prune from the tree</p> required <p>Returns:</p> Type Description <code>Node</code> <p>The pruned node (which is no longer part of the tree). If parent was pruned, the parent will be returned.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node is not found in the tree or if attempting to prune the root node</p> Source code in <code>okapi/tree.py</code> <pre><code>def prune_at(self, node: Node) -&gt; Node:\n    \"\"\"\n    Remove a node and its subtree from the tree.\n\n    This method removes the specified node and all its descendants from the tree.\n    If the node is the only child of an operator node, that operator node will\n    also be pruned.\n\n    Args:\n        node: The node to prune from the tree\n\n    Returns:\n        The pruned node (which is no longer part of the tree). If parent was pruned, the parent will be returned.\n\n    Raises:\n        ValueError: If the node is not found in the tree or if attempting to prune the root node\n    \"\"\"\n    logger.debug(f\"Pruning node from tree: {node}\")\n\n    if node not in self.nodes[\"value_nodes\"] and node not in self.nodes[\"op_nodes\"]:\n        logger.error(f\"Attempted to prune node not in tree: {node}\")\n        raise ValueError(\"Node not found in tree\")\n\n    if node.parent is None:\n        logger.error(\"Cannot prune root node\")\n        raise ValueError(\"Cannot prune root node\")\n\n    if isinstance(node.parent, OperatorNode) and (\n        len(node.parent.children) &lt; 2\n    ):  # if only child of op node is to be pruned, remove the parent instead\n        logger.debug(f\"Node is the only child of operator node, pruning parent: {node.parent}\")\n        return self.prune_at(node.parent)\n\n    subtree_nodes = node.get_nodes()\n    node_count = len(subtree_nodes)\n\n    logger.debug(f\"Removing {node_count} nodes in subtree\")\n    for subtree_node in subtree_nodes:\n        if isinstance(subtree_node, ValueNode):\n            self.nodes[\"value_nodes\"].remove(subtree_node)\n        else:\n            self.nodes[\"op_nodes\"].remove(subtree_node)\n\n    node.parent.remove_child(node)\n    logger.debug(\"Pruning complete, clearing cached evaluations\")\n    self._clean_evals()\n    return node\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.recalculate","title":"<code>recalculate()</code>","text":"<p>Force recalculation of the tree evaluation.</p> <p>This method clears any cached evaluations and triggers a fresh calculation. It also updates the nodes dictionary</p> <p>Returns:</p> Type Description <p>The newly calculated evaluation of the tree</p> Source code in <code>okapi/tree.py</code> <pre><code>def recalculate(self):\n    \"\"\"\n    Force recalculation of the tree evaluation.\n\n    This method clears any cached evaluations and triggers a fresh calculation.\n    It also updates the nodes dictionary\n\n    Returns:\n        The newly calculated evaluation of the tree\n    \"\"\"\n    logger.debug(\"Recalculating tree evaluation\")\n    self._clean_evals()\n    self.update_nodes()\n    evaluation = self.evaluation\n    logger.trace(\"Tree recalculation complete\")\n    return evaluation\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.replace_at","title":"<code>replace_at(at, replacement)</code>","text":"<p>Replace a node in the tree with another node.</p> <p>The replacement node must be of the same type as the node being replaced. This operation preserves the parent-child relationships.</p> <p>Parameters:</p> Name Type Description Default <code>at</code> <code>Node</code> <p>The node to be replaced</p> required <code>replacement</code> <code>Node</code> <p>The new node that will replace the existing node</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Self reference to allow method chaining</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the replacement node is not of the same type as the node being replaced</p> Source code in <code>okapi/tree.py</code> <pre><code>def replace_at(self, at: Node, replacement: Node) -&gt; Self:\n    \"\"\"\n    Replace a node in the tree with another node.\n\n    The replacement node must be of the same type as the node being replaced.\n    This operation preserves the parent-child relationships.\n\n    Args:\n        at: The node to be replaced\n        replacement: The new node that will replace the existing node\n\n    Returns:\n        Self reference to allow method chaining\n\n    Raises:\n        AssertionError: If the replacement node is not of the same type as the node being replaced\n    \"\"\"\n    assert (isinstance(replacement, ValueNode) and isinstance(at, ValueNode)) or (\n        isinstance(replacement, OperatorNode) and isinstance(at, OperatorNode)\n    ), \"Replacement node must be of the same parent type (ValueNode or OperatorNode) as the node being replaced\"\n    at_parent = at.parent\n\n    if at_parent is None:\n        assert isinstance(self.root, ValueNode), \"Root must be a value node\"\n        assert isinstance(replacement, ValueNode), \"Replacement for root must be a value node\"\n        logger.warning(\"Node at replacement is root node\")\n        self.root = replacement\n    else:\n        at_parent.replace_child(at, replacement)\n\n    if isinstance(at, ValueNode):\n        self.nodes[\"value_nodes\"].remove(at)\n        self.nodes[\"value_nodes\"].append(replacement)\n    else:\n        self.nodes[\"op_nodes\"].remove(at)\n        self.nodes[\"op_nodes\"].append(replacement)\n\n    self._clean_evals()\n    return self\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.save_tree_architecture","title":"<code>save_tree_architecture(output_path)</code>","text":"<p>Save the tree's architecture to a file.</p> <p>This method creates a copy of the tree with tensor values removed and saves it to the specified path using pickle serialization.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <p>Path where the tree architecture will be saved</p> required Source code in <code>okapi/tree.py</code> <pre><code>def save_tree_architecture(self, output_path):  # TODO: needs adjustment for weighted node\n    \"\"\"\n    Save the tree's architecture to a file.\n\n    This method creates a copy of the tree with tensor values removed\n    and saves it to the specified path using pickle serialization.\n\n    Args:\n        output_path: Path where the tree architecture will be saved\n    \"\"\"\n    logger.info(f\"Saving tree architecture to {output_path}\")\n    copy_tree = self.copy()\n    copy_tree._clean_values_and_evals()\n\n    Pickle.save(output_path, copy_tree)\n    logger.debug(\"Tree architecture saved successfully\")\n</code></pre>"},{"location":"api/core/#okapi.tree.Tree.update_nodes","title":"<code>update_nodes()</code>","text":"<p>Update the internal collections of nodes in the tree.</p> <p>This method traverses the tree and categorizes all nodes into value nodes and operator nodes, updating the internal <code>nodes</code> dictionary.</p> Source code in <code>okapi/tree.py</code> <pre><code>def update_nodes(self):\n    \"\"\"\n    Update the internal collections of nodes in the tree.\n\n    This method traverses the tree and categorizes all nodes into value nodes and operator nodes,\n    updating the internal `nodes` dictionary.\n    \"\"\"\n    logger.debug(\"Updating tree node collections\")\n    self.nodes = {\"value_nodes\": [], \"op_nodes\": []}\n    root_nodes = self.root.get_nodes()\n    for node in root_nodes:\n        if isinstance(node, ValueNode):\n            self.nodes[\"value_nodes\"].append(node)\n        else:\n            self.nodes[\"op_nodes\"].append(node)\n    logger.trace(f\"Updated nodes: {len(self.nodes['value_nodes'])} value nodes, {len(self.nodes['op_nodes'])} operator nodes\")\n</code></pre>"},{"location":"api/evolution/","title":"Evolution API","text":"<p>This section documents the evolutionary components of OKAPI.</p>"},{"location":"api/evolution/#population","title":"Population","text":"<p>Functions for initializing and managing populations of trees.</p> <pre><code>from okapi.population import initialize_individuals, choose_n_best, choose_pareto, choose_pareto_then_sorted\n</code></pre>"},{"location":"api/evolution/#okapi.population.choose_pareto","title":"<code>choose_pareto(trees, fitnesses, n, objectives, minimize_node_count=True)</code>","text":"<p>Select up to n trees based on Pareto optimality. Optimizes for: - Maximizing fitness - Minimizing number of nodes in the tree</p> <p>Parameters:</p> Name Type Description Default <code>trees</code> <code>List[Tree]</code> <p>List of Tree objects</p> required <code>fitnesses</code> <code>ndarray</code> <p>Array of fitness values for each tree</p> required <code>n</code> <code>int</code> <p>Maximum number of trees to select</p> required <p>Returns:</p> Type Description <p>List of selected trees and their corresponding fitness values</p> Source code in <code>okapi/population.py</code> <pre><code>def choose_pareto(trees: List[Tree], fitnesses: np.ndarray, n: int, objectives: Sequence[Callable[[float, float], bool]], minimize_node_count=True):\n    \"\"\"\n    Select up to n trees based on Pareto optimality.\n    Optimizes for:\n    - Maximizing fitness\n    - Minimizing number of nodes in the tree\n\n    Args:\n        trees: List of Tree objects\n        fitnesses: Array of fitness values for each tree\n        n: Maximum number of trees to select\n\n    Returns:\n        List of selected trees and their corresponding fitness values\n    \"\"\"\n    logger.debug(f\"Selecting up to {n} Pareto-optimal trees from population of {len(trees)}\")\n\n    objectives = list(objectives)\n    if minimize_node_count:\n        objectives.append(minimize)\n        sizes = np.array([tree.nodes_count for tree in trees]).reshape(-1, 1)\n        objective_array = np.concatenate([fitnesses, sizes], axis=1)\n    else:\n        objective_array = fitnesses\n\n    # Get Pareto-optimal mask using maximize for fitness and minimize for nodes count\n    pareto_mask = paretoset(objective_array, objectives)\n    pareto_count = np.sum(pareto_mask)\n    logger.debug(f\"Found {pareto_count} Pareto-optimal trees\")\n\n    # Get indices of Pareto-optimal trees\n    pareto_indices = np.where(pareto_mask)[0]\n\n    # If we have more Pareto-optimal trees than n, select the n with highest fitness\n    if len(pareto_indices) &gt; n:\n        logger.debug(f\"Too many Pareto-optimal trees ({len(pareto_indices)}), selecting top {n} by proximity\")\n        if minimize_node_count:\n            objectives = objectives[:-1]\n        _, sorted_indices = sort_by_optimal_point_proximity(fitnesses, objectives)\n        selected_indices = sorted_indices[:n]\n    else:\n        selected_indices = pareto_indices\n        logger.debug(f\"Using all {len(selected_indices)} Pareto-optimal trees\")\n\n    # Return selected trees and their fitnesses, for now allow for duplicates with regards to fitrnesses\n\n    selected_fitnesses = fitnesses[selected_indices]\n    # uniques_mask = first_uniques_mask(selected_fitnesses)\n\n    # selected_indices = selected_indices[uniques_mask]\n\n    selected_trees = [trees[i] for i in selected_indices]\n    # selected_fitnesses = fitnesses[selected_indices]\n\n    if len(selected_trees) &gt; 0:\n        logger.debug(f\"Selected {len(selected_trees)} trees with fitness range: {selected_fitnesses.min():.4f} - {selected_fitnesses.max():.4f}\")\n    else:\n        logger.warning(\"No trees selected in Pareto optimization\")\n\n    return selected_trees, selected_fitnesses\n</code></pre>"},{"location":"api/evolution/#okapi.population.initialize_individuals","title":"<code>initialize_individuals(tensors_dict, n, exclude_ids=tuple())</code>","text":"<p>Initialize a population of individuals (trees) from a dictionary of tensors.</p> <p>This function creates simple trees, each with a root node containing a different tensor from the provided dictionary. The tensors are selected randomly from the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>tensors_dict</code> <code>Dict[str, Tensor]</code> <p>Dictionary mapping model IDs to their tensor representations</p> required <code>n</code> <code>int</code> <p>Number of individuals (trees) to create</p> required <code>exclude_ids</code> <p>Optional tuple of model IDs to exclude from selection</p> <code>tuple()</code> <p>Returns:</p> Type Description <code>List[Tree]</code> <p>List of initialized Tree objects</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If n is greater than the number of available tensors after exclusions</p> Source code in <code>okapi/population.py</code> <pre><code>def initialize_individuals(tensors_dict: Dict[str, Tensor], n: int, exclude_ids=tuple()) -&gt; List[Tree]:\n    \"\"\"\n    Initialize a population of individuals (trees) from a dictionary of tensors.\n\n    This function creates simple trees, each with a root node containing a different tensor\n    from the provided dictionary. The tensors are selected randomly from the dictionary.\n\n    Args:\n        tensors_dict: Dictionary mapping model IDs to their tensor representations\n        n: Number of individuals (trees) to create\n        exclude_ids: Optional tuple of model IDs to exclude from selection\n\n    Returns:\n        List of initialized Tree objects\n\n    Raises:\n        Exception: If n is greater than the number of available tensors after exclusions\n    \"\"\"\n    logger.info(f\"Initializing {n} individuals\")\n    logger.debug(f\"Available tensors: {len(tensors_dict)}, excluded IDs: {len(exclude_ids)}\")\n\n    order = np.arange(len(tensors_dict))\n    np.random.shuffle(order)\n    logger.trace(\"Shuffled tensor order\")\n\n    ids_list = list(tensors_dict.keys())\n    tensors_list = list(tensors_dict.values())\n\n    new_trees = []\n    count = 0\n    for idx in order:\n        _id = ids_list[idx]\n        tensor = tensors_list[idx]\n        if count &gt;= n:\n            break\n        if _id in exclude_ids:\n            logger.trace(f\"Skipping excluded ID: {_id}\")\n            continue\n\n        logger.debug(f\"Creating tree with tensor ID: {_id}\")\n        root: ValueNode = ValueNode(children=None, value=tensor, id=_id)\n        tree = Tree.create_tree_from_root(root)\n        new_trees.append(tree)\n        count += 1\n\n    if count &lt; n:\n        logger.error(f\"Could not generate enough individuals. Requested: {n}, generated: {count}\")\n        raise Exception(\"Could not generate as many examples\")\n\n    logger.info(f\"Successfully initialized {len(new_trees)} individuals\")\n    return new_trees\n</code></pre>"},{"location":"api/evolution/#crossover","title":"Crossover","text":"<p>Functions for performing crossover between trees.</p> <pre><code>from okapi.crossover import crossover, tournament_selection_indexes\n</code></pre>"},{"location":"api/evolution/#okapi.crossover.crossover","title":"<code>crossover(tree1, tree2, node_type=None)</code>","text":"<p>Performs crossover between two parent trees to produce two offspring trees.</p> <p>Crossover works by selecting a random node from each parent tree and swapping the subtrees rooted at those nodes. This creates two new offspring trees that contain genetic material from both parents.</p> <p>Parameters:</p> Name Type Description Default <code>tree1</code> <code>Tree</code> <p>First parent tree</p> required <code>tree2</code> <code>Tree</code> <p>Second parent tree</p> required <code>node_type</code> <p>Type of nodes to consider for crossover points ('value_nodes' or 'op_nodes').        If None, a random suitable type will be chosen.</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple of two new Tree objects created by crossover</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If node_type is 'op_nodes' but one or both trees don't have operator nodes</p> Source code in <code>okapi/crossover.py</code> <pre><code>def crossover(tree1: Tree, tree2: Tree, node_type=None):\n    \"\"\"\n    Performs crossover between two parent trees to produce two offspring trees.\n\n    Crossover works by selecting a random node from each parent tree and swapping\n    the subtrees rooted at those nodes. This creates two new offspring trees that\n    contain genetic material from both parents.\n\n    Args:\n        tree1: First parent tree\n        tree2: Second parent tree\n        node_type: Type of nodes to consider for crossover points ('value_nodes' or 'op_nodes').\n                   If None, a random suitable type will be chosen.\n\n    Returns:\n        Tuple of two new Tree objects created by crossover\n\n    Raises:\n        ValueError: If node_type is 'op_nodes' but one or both trees don't have operator nodes\n    \"\"\"\n    logger.info(\"Performing crossover between two trees\")\n\n    if node_type is None:\n        allowable_node_types = [\"value_nodes\"]  # TODO: this may be worth refactoring along with \"get_random_node\" to not use string but types instead\n\n        if (len(tree1.nodes[\"op_nodes\"]) &gt; 0) &amp; (len(tree2.nodes[\"op_nodes\"]) &gt; 0):\n            allowable_node_types.append(\"op_nodes\")\n            logger.debug(\"Both trees have operator nodes, including them in potential crossover points\")\n        else:\n            logger.debug(\"At least one tree has no operator nodes, using only value nodes for crossover\")\n\n        nodes_type = np.random.choice(allowable_node_types)\n        logger.debug(f\"Randomly selected node type for crossover: {nodes_type}\")\n    else:\n        if node_type == \"op_nodes\" and not ((len(tree1.nodes[\"op_nodes\"]) &gt; 0) &amp; (len(tree2.nodes[\"op_nodes\"]) &gt; 0)):\n            logger.error(\"Node type was chosen to be operator nodes but there are no operator nodes in at least one of the parents\")\n            raise ValueError(\"Node type was chosen to be operator nodes but there are not operator nodes in at least one of the parents\")\n        nodes_type = node_type\n        logger.debug(f\"Using specified node type for crossover: {nodes_type}\")\n\n    logger.debug(\"Creating copies of parent trees\")\n    tree1, tree2 = tree1.copy(), tree2.copy()\n\n    logger.debug(\"Selecting random nodes for crossover\")\n    node1, node2 = tree1.get_random_node(nodes_type), tree2.get_random_node(nodes_type)\n    logger.debug(f\"Selected nodes: {node1} from tree1, {node2} from tree2\")\n\n    logger.debug(\"Creating copies of subtrees\")\n    branch1, branch2 = node1.copy_subtree(), node2.copy_subtree()\n\n    logger.debug(\"Swapping subtrees between trees\")\n    tree1.replace_at(node1, branch2).recalculate()\n    tree2.replace_at(node2, branch1).recalculate()\n\n    logger.info(f\"Crossover complete, created two new trees with {tree1.nodes_count} and {tree2.nodes_count} nodes\")\n    return tree1, tree2\n</code></pre>"},{"location":"api/evolution/#okapi.crossover.tournament_selection_indexes","title":"<code>tournament_selection_indexes(fitnesses, tournament_size=5, optimal_point=None)</code>","text":"<p>Selects parent indices for crossover using tournament selection.</p> <p>In tournament selection, a subset of individuals (of size tournament_size) is randomly selected from the population, and the one with the highest fitness is chosen as a parent. This process is repeated to select the second parent.</p> <p>Parameters:</p> Name Type Description Default <code>fitnesses</code> <code>ndarray</code> <p>Array of fitness values for the entire population</p> required <code>tournament_size</code> <code>int</code> <p>Number of individuals to include in each tournament</p> <code>5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with indices of the two selected parents</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If tournament_size is too large relative to population size</p> Source code in <code>okapi/crossover.py</code> <pre><code>def tournament_selection_indexes(fitnesses: np.ndarray, tournament_size: int = 5, optimal_point: np.ndarray | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Selects parent indices for crossover using tournament selection.\n\n    In tournament selection, a subset of individuals (of size tournament_size) is randomly\n    selected from the population, and the one with the highest fitness is chosen as a parent.\n    This process is repeated to select the second parent.\n\n    Args:\n        fitnesses: Array of fitness values for the entire population\n        tournament_size: Number of individuals to include in each tournament\n\n    Returns:\n        Array with indices of the two selected parents\n\n    Raises:\n        ValueError: If tournament_size is too large relative to population size\n    \"\"\"\n    logger.debug(f\"Running tournament selection with tournament size {tournament_size}\")\n\n    if tournament_size &gt; (len(fitnesses)):\n        logger.error(f\"Tournament size {tournament_size} is too large for population size {len(fitnesses)}\")\n        raise ValueError(f\"Size of the tournament should be at most equal to number of participans but {len(fitnesses)=} and {tournament_size=}\")\n\n    if len(fitnesses) &lt; (2 * tournament_size):\n        logger.warning(\n            f\"Tournament size ({tournament_size}), is small related to the population size ({len(fitnesses)}).\"\n            \"The population should be at least twice as large as tournament for more stable parent selection\"\n        )\n\n    if optimal_point is None:\n        optimal_point = np.ones(shape=(fitnesses.shape[-1],))\n    assert len(optimal_point.shape) == 1 and fitnesses.shape[-1] == optimal_point.shape[-1], \"Shapes for fitnesses and optimal point do not match\"\n\n    selected: list | np.ndarray = []\n    for _ in range(2):\n        candidates_idx = np.random.choice(np.arange(len(fitnesses)), size=(tournament_size,), replace=False)\n        candidates_fitnesses = fitnesses[candidates_idx]\n        distances = _euclidean_distances(candidates_fitnesses, optimal_point)\n        best_idx = np.argmin(distances)\n        assert isinstance(selected, list)\n        selected.append(candidates_idx[best_idx])\n    selected = np.array(selected)\n\n    assert selected.shape == (2,)\n\n    logger.debug(f\"Selected parent indices: {selected}\")\n    return selected\n</code></pre>"},{"location":"api/evolution/#mutation","title":"Mutation","text":"<p>Functions for mutating trees.</p> <pre><code>from okapi.mutation import append_new_node_mutation, lose_branch_mutation, new_tree_from_branch_mutation, get_allowed_mutations\n</code></pre>"},{"location":"api/evolution/#okapi.mutation.append_new_node_mutation","title":"<code>append_new_node_mutation(tree, models, ids=None, allowed_ops=(MeanNode,), **kwargs)</code>","text":"<p>Mutation that adds a new node to the tree.</p> <p>This mutation randomly selects an existing node in the tree and appends a new node as its child. If the selected node is a ValueNode, a new OperatorNode is created as an intermediary, and the new ValueNode is added as its child. If the selected node is an OperatorNode, a new ValueNode is directly appended to it.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree to mutate</p> required <code>models</code> <code>Sequence[Tensor]</code> <p>Sequence of tensor models that can be used as values for the new ValueNode</p> required <code>ids</code> <code>None | Sequence[str | int]</code> <p>Optional sequence of identifiers for the models. If None, indices will be used</p> <code>None</code> <code>allowed_ops</code> <code>tuple[Type[OperatorNode], ...]</code> <p>Tuple of OperatorNode types that can be used when creating a new operator node</p> <code>(MeanNode,)</code> <code>**kwargs</code> <p>Additional keyword arguments (ignored)</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new Tree with the mutation applied</p> Source code in <code>okapi/mutation.py</code> <pre><code>def append_new_node_mutation(\n    tree: Tree, models: Sequence[Tensor], ids: None | Sequence[str | int] = None, allowed_ops: tuple[Type[OperatorNode], ...] = (MeanNode,), **kwargs\n):\n    \"\"\"\n    Mutation that adds a new node to the tree.\n\n    This mutation randomly selects an existing node in the tree and appends a new node as its\n    child. If the selected node is a ValueNode, a new OperatorNode is created as an intermediary,\n    and the new ValueNode is added as its child. If the selected node is an OperatorNode,\n    a new ValueNode is directly appended to it.\n\n    Args:\n        tree: The tree to mutate\n        models: Sequence of tensor models that can be used as values for the new ValueNode\n        ids: Optional sequence of identifiers for the models. If None, indices will be used\n        allowed_ops: Tuple of OperatorNode types that can be used when creating a new operator node\n        **kwargs: Additional keyword arguments (ignored)\n\n    Returns:\n        A new Tree with the mutation applied\n    \"\"\"\n    logger.debug(\"Applying append_new_node_mutation\")\n    tree = tree.copy()\n\n    if ids is None:\n        ids = list(range(len(models)))\n        logger.trace(\"Using indices as IDs for models\")\n    else:\n        assert len(models) == len(ids)\n        logger.trace(f\"Using provided IDs, confirmed length match: {len(ids)}\")\n\n    idx_model = np.random.randint(len(ids))\n    logger.debug(f\"Selected model ID: {ids[idx_model]}\")\n    node = tree.get_random_node()\n    logger.debug(f\"Selected random node for mutation: {node}\")\n\n    val_node: ValueNode = ValueNode([], models[idx_model], ids[idx_model])\n    logger.trace(f\"Created new value node with ID: {ids[idx_model]}\")\n\n    if isinstance(node, ValueNode):\n        random_op: Type[OperatorNode] = np.random.choice(np.asarray(allowed_ops))\n        logger.debug(f\"Selected random operator type: {random_op.__name__}\")\n        op_node: OperatorNode = random_op.create_node([val_node])\n        logger.debug(\"Appending operator node with value node child after selected node\")\n        tree.append_after(node, op_node)\n    else:\n        logger.debug(\"Appending value node directly to operator node\")\n        tree.append_after(node, val_node)\n\n    logger.info(f\"Append node mutation complete, new tree has {tree.nodes_count} nodes\")\n    return tree\n</code></pre>"},{"location":"api/evolution/#okapi.mutation.get_allowed_mutations","title":"<code>get_allowed_mutations(tree)</code>","text":"<p>Determines which mutation operations are valid for a given tree.</p> <p>This function checks the tree's structure and size to determine which mutations can be safely applied without violating constraints.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <p>The tree to analyze</p> required <p>Returns:</p> Type Description <p>A list of mutation functions that are valid for the given tree</p> Source code in <code>okapi/mutation.py</code> <pre><code>def get_allowed_mutations(tree):\n    \"\"\"\n    Determines which mutation operations are valid for a given tree.\n\n    This function checks the tree's structure and size to determine which mutations\n    can be safely applied without violating constraints.\n\n    Args:\n        tree: The tree to analyze\n\n    Returns:\n        A list of mutation functions that are valid for the given tree\n    \"\"\"\n    logger.debug(f\"Determining allowed mutations for tree with {tree.nodes_count} nodes\")\n    allowed_mutations: list[Callable] = [\n        append_new_node_mutation,\n    ]\n\n    if tree.nodes_count &gt;= 3:\n        logger.trace(\"Tree is large enough for lose_branch_mutation\")\n        allowed_mutations.append(lose_branch_mutation)\n    if len(tree.nodes[\"value_nodes\"]) &gt; 1:\n        logger.trace(\"Tree has enough value nodes for new_tree_from_branch_mutation\")\n        allowed_mutations.append(new_tree_from_branch_mutation)\n\n    logger.debug(f\"Found {len(allowed_mutations)} allowed mutation types\")\n    return allowed_mutations\n</code></pre>"},{"location":"api/evolution/#okapi.mutation.lose_branch_mutation","title":"<code>lose_branch_mutation(tree, **kwargs)</code>","text":"<p>Mutation that removes a branch from the tree.</p> <p>This mutation randomly selects a non-root, non-leaf node in the tree and removes it along with all its descendants, effectively pruning that branch from the tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree to mutate</p> required <code>**kwargs</code> <p>Additional keyword arguments (ignored)</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new Tree with the mutation applied</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the tree has fewer than 3 nodes</p> Source code in <code>okapi/mutation.py</code> <pre><code>def lose_branch_mutation(tree: Tree, **kwargs):\n    \"\"\"\n    Mutation that removes a branch from the tree.\n\n    This mutation randomly selects a non-root, non-leaf node in the tree and removes it along\n    with all its descendants, effectively pruning that branch from the tree.\n\n    Args:\n        tree: The tree to mutate\n        **kwargs: Additional keyword arguments (ignored)\n\n    Returns:\n        A new Tree with the mutation applied\n\n    Raises:\n        AssertionError: If the tree has fewer than 3 nodes\n    \"\"\"\n    logger.debug(\"Applying lose_branch_mutation\")\n    tree = tree.copy()\n\n    if tree.nodes_count &lt; 3:\n        logger.error(f\"Cannot apply lose_branch_mutation - tree is too small: {tree.nodes_count} nodes\")\n        assert tree.nodes_count &gt;= 3, \"Tree is too small\"\n\n    node = tree.get_random_node(allow_leaves=False, allow_root=False)\n    logger.debug(f\"Selected node for pruning: {node}\")\n\n    pruned = tree.prune_at(node)\n    logger.info(f\"Pruned branch with {len(pruned.get_nodes())} nodes, tree now has {tree.nodes_count} nodes\")\n\n    return tree\n</code></pre>"},{"location":"api/evolution/#okapi.mutation.new_tree_from_branch_mutation","title":"<code>new_tree_from_branch_mutation(tree, **kwargs)</code>","text":"<p>Mutation that creates a new tree from a branch of the existing tree.</p> <p>This mutation randomly selects a non-root ValueNode, removes it from the tree along with its descendants, and creates a new tree with the removed node as its root.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree to mutate</p> required <code>**kwargs</code> <p>Additional keyword arguments (ignored)</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new Tree created from the selected branch</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the tree has only one ValueNode</p> Source code in <code>okapi/mutation.py</code> <pre><code>def new_tree_from_branch_mutation(tree: Tree, **kwargs):\n    \"\"\"\n    Mutation that creates a new tree from a branch of the existing tree.\n\n    This mutation randomly selects a non-root ValueNode, removes it from the tree along with\n    its descendants, and creates a new tree with the removed node as its root.\n\n    Args:\n        tree: The tree to mutate\n        **kwargs: Additional keyword arguments (ignored)\n\n    Returns:\n        A new Tree created from the selected branch\n\n    Raises:\n        AssertionError: If the tree has only one ValueNode\n    \"\"\"\n    assert len(tree.nodes[\"value_nodes\"]) &gt; 1, \"Tree must have more than one value node\"\n\n    logger.debug(\"Applying new_tree_from_branch_mutation\")\n    tree = tree.copy()\n\n    node = tree.get_random_node(nodes_type=\"value_nodes\", allow_leaves=True, allow_root=False)\n    logger.debug(f\"Selected value node for creating new tree: {node}\")\n\n    _ = tree.prune_at(node)  # this may return parent op node, so we still want to use the original node.\n    logger.debug(\"Pruned node and its subtree to create new tree\")\n\n    assert isinstance(node, ValueNode)\n    new_tree = Tree.create_tree_from_root(node)\n\n    logger.info(f\"Created new tree from branch with {new_tree.nodes_count} nodes\")\n    return new_tree\n</code></pre>"},{"location":"api/evolution/#pareto-optimization","title":"Pareto Optimization","text":"<p>Functions for Pareto optimization and visualization.</p> <pre><code>from okapi.pareto import paretoset, minimize, maximize, plot_pareto_frontier\n</code></pre>"},{"location":"api/evolution/#okapi.pareto.maximize","title":"<code>maximize(a, b)</code>","text":"<p>Compare two values for maximization in Pareto optimization.</p> <p>This function determines if the first value (a) is at least as good as the second value (b) in the context of maximization (higher is better).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <p>First value to compare</p> required <code>b</code> <p>Second value to compare</p> required <p>Returns:</p> Type Description <p>True if a is greater than or equal to b, False otherwise</p> Source code in <code>okapi/pareto.py</code> <pre><code>def maximize(a, b):\n    \"\"\"\n    Compare two values for maximization in Pareto optimization.\n\n    This function determines if the first value (a) is at least as good as\n    the second value (b) in the context of maximization (higher is better).\n\n    Args:\n        a: First value to compare\n        b: Second value to compare\n\n    Returns:\n        True if a is greater than or equal to b, False otherwise\n    \"\"\"\n    return a &gt;= b\n</code></pre>"},{"location":"api/evolution/#okapi.pareto.minimize","title":"<code>minimize(a, b)</code>","text":"<p>Compare two values for minimization in Pareto optimization.</p> <p>This function determines if the first value (a) is at least as good as the second value (b) in the context of minimization (lower is better).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <p>First value to compare</p> required <code>b</code> <p>Second value to compare</p> required <p>Returns:</p> Type Description <p>True if a is less than or equal to b, False otherwise</p> Source code in <code>okapi/pareto.py</code> <pre><code>def minimize(a, b):\n    \"\"\"\n    Compare two values for minimization in Pareto optimization.\n\n    This function determines if the first value (a) is at least as good as\n    the second value (b) in the context of minimization (lower is better).\n\n    Args:\n        a: First value to compare\n        b: Second value to compare\n\n    Returns:\n        True if a is less than or equal to b, False otherwise\n    \"\"\"\n    return a &lt;= b\n</code></pre>"},{"location":"api/evolution/#okapi.pareto.paretoset","title":"<code>paretoset(array, objectives)</code>","text":"<p>Identify the Pareto-optimal set from a collection of points with multiple objectives.</p> <p>This function finds points that are not dominated by any other point, where dominance is determined based on the specified objective functions. A point dominates another if it is at least as good in all objectives and strictly better in at least one.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>2D array where each row is a point and each column represents a different objective</p> required <code>objectives</code> <code>Sequence[Callable[[float, float], bool]]</code> <p>Sequence of objective functions (maximize or minimize) for each column</p> required <p>Returns:</p> Type Description <p>Boolean mask where True indicates a point belongs to the Pareto-optimal set</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If dimensions don't match or the array is not 2D</p> Source code in <code>okapi/pareto.py</code> <pre><code>def paretoset(array: np.ndarray, objectives: Sequence[Callable[[float, float], bool]]):\n    \"\"\"\n    Identify the Pareto-optimal set from a collection of points with multiple objectives.\n\n    This function finds points that are not dominated by any other point, where dominance\n    is determined based on the specified objective functions. A point dominates another\n    if it is at least as good in all objectives and strictly better in at least one.\n\n    Args:\n        array: 2D array where each row is a point and each column represents a different objective\n        objectives: Sequence of objective functions (maximize or minimize) for each column\n\n    Returns:\n        Boolean mask where True indicates a point belongs to the Pareto-optimal set\n\n    Raises:\n        AssertionError: If dimensions don't match or the array is not 2D\n    \"\"\"\n    assert len(array.shape) == 2, \"Array should be one dimensional, where first dimension is number of points, second dimension number of objectives\"\n\n    n_points, n_objectives = array.shape\n\n    assert len(objectives) == n_objectives\n\n    domination_mask = [True for _ in range(n_points)]\n\n    for i in range(n_points):  # checking if ith point should be on the pareto front\n        for j in range(n_points):\n            if i == j:\n                continue\n            if np.array_equal(array[i], array[j]):\n                continue\n\n            point_domination_mask = [f(array[j, k], array[i, k]) for k, f in enumerate(objectives)]\n            if all(point_domination_mask):  # j dominates i because at least as good at all objectives\n                domination_mask[i] = False\n                break\n    return domination_mask\n</code></pre>"},{"location":"api/evolution/#okapi.pareto.plot_pareto_frontier","title":"<code>plot_pareto_frontier(array, objectives, figsize=(10, 6), title='Pareto Frontier')</code>","text":"<p>Visualize the Pareto frontier for a two-dimensional optimization problem.</p>"},{"location":"api/evolution/#okapi.pareto.plot_pareto_frontier--parameters","title":"Parameters:","text":"<p>array : np.ndarray     Array of points where the first dimension is the number of points and     the second dimension must be exactly 2 (two criteria to optimize). objectives : Sequence[Callable]     Sequence of two objective functions, each should be either maximize or minimize. figsize : tuple, optional     Size of the figure (width, height) in inches. Default is (10, 6). title : str, optional     Title of the plot. Default is \"Pareto Frontier\".</p>"},{"location":"api/evolution/#okapi.pareto.plot_pareto_frontier--returns","title":"Returns:","text":"<p>fig, ax : tuple     Matplotlib figure and axes objects.</p> Source code in <code>okapi/pareto.py</code> <pre><code>def plot_pareto_frontier(array: np.ndarray, objectives: Sequence[Callable[[float, float], bool]], figsize=(10, 6), title=\"Pareto Frontier\"):\n    \"\"\"\n    Visualize the Pareto frontier for a two-dimensional optimization problem.\n\n    Parameters:\n    -----------\n    array : np.ndarray\n        Array of points where the first dimension is the number of points and\n        the second dimension must be exactly 2 (two criteria to optimize).\n    objectives : Sequence[Callable]\n        Sequence of two objective functions, each should be either maximize or minimize.\n    figsize : tuple, optional\n        Size of the figure (width, height) in inches. Default is (10, 6).\n    title : str, optional\n        Title of the plot. Default is \"Pareto Frontier\".\n\n    Returns:\n    --------\n    fig, ax : tuple\n        Matplotlib figure and axes objects.\n    \"\"\"\n    assert len(array.shape) == 2, \"Array should be two-dimensional\"\n    assert array.shape[1] == 2, \"This function only works for two criteria (array.shape[1] must be 2)\"\n    assert len(objectives) == 2, \"This function only works for two objectives\"\n\n    # Get the Pareto set (True for points on the Pareto frontier)\n    pareto_mask = paretoset(array, objectives)\n\n    # Create figure and axis\n    fig, ax = plt.subplots(figsize=figsize)\n\n    # Extract Pareto and non-Pareto points\n    pareto_points = array[pareto_mask]\n    non_pareto_points = array[np.logical_not(pareto_mask)]\n\n    # Plot non-Pareto points in blue\n    if len(non_pareto_points) &gt; 0:\n        ax.scatter(non_pareto_points[:, 0], non_pareto_points[:, 1], color=\"blue\", label=\"Non-Pareto points\")\n\n    # Plot Pareto points in red\n    if len(pareto_points) &gt; 0:\n        ax.scatter(pareto_points[:, 0], pareto_points[:, 1], color=\"red\", label=\"Pareto frontier points\")\n\n        # Sort points for line drawing based on the objectives\n        # For two objectives, we typically want to sort by one coordinate\n        # The sort direction depends on whether we're maximizing or minimizing\n        sort_col = 0\n        sort_ascending = isinstance(objectives[0], type(minimize))\n\n        # Sort the Pareto points\n        sorted_indices = np.argsort(pareto_points[:, sort_col])\n        if not sort_ascending:\n            sorted_indices = sorted_indices[::-1]\n\n        sorted_pareto = pareto_points[sorted_indices]\n\n        # Draw the line connecting Pareto points\n        ax.plot(sorted_pareto[:, 0], sorted_pareto[:, 1], color=\"red\", linestyle=\"-\", linewidth=2)\n\n    # Add labels and title\n    ax.set_xlabel(\"Criterion 1\")\n    ax.set_ylabel(\"Criterion 2\")\n    ax.set_title(title)\n    ax.legend()\n    ax.grid(True, linestyle=\"--\", alpha=0.7)\n\n    return fig, ax\n</code></pre>"},{"location":"api/nodes/","title":"Nodes API","text":"<p>Nodes are the fundamental building blocks of trees in OKAPI. This section documents the different types of nodes available.</p>"},{"location":"api/nodes/#base-node-class","title":"Base Node Class","text":"<p>The <code>Node</code> class is the base class for all node types in OKAPI.</p> <pre><code>from okapi.node import Node\n</code></pre> <p>Nodes act as the fundamental building blocks of a tree, capable of holding children and a reference to their parent node.</p> <p>When created, parent reference cannot be specified. The reason for it is to create uniderectional responsibility for link creation. A node should be responsible for creating and breaking links with its children, by setting their parent links.</p> <p>Attributes:</p> Name Type Description <code>parent</code> <code>Union[Node, None]</code> <p>A reference to a parent node, of which this node is a child.</p> <code>children</code> <code>List[Node]</code> <p>A list of references to a children nodes.</p> Source code in <code>okapi/node.py</code> <pre><code>class Node:\n    \"\"\"\n    Nodes act as the fundamental building blocks of a tree,\n    capable of holding children and a reference to their parent node.\n\n    When created, parent reference cannot be specified. The reason for it is to create uniderectional\n    responsibility for link creation. A node should be responsible for creating and breaking links with its children,\n    by setting their parent links.\n\n    Attributes:\n        parent (Union[Node, None]): A reference to a parent node, of which this node is a child.\n        children (List[Node]): A list of references to a children nodes.\n    \"\"\"\n\n    def __init__(self, children: Optional[Sequence[\"Node\"]] = None):\n        \"\"\"\n        Create a node\n\n        Args:\n            children (Optional[Sequence[\"Node\"]]): An optional list like sequence of children of the node\n        \"\"\"\n        self.parent: Union[Node, None] = None\n        self.children: List[Node] = list(children) if children is not None else []\n\n        for child in self.children:\n            child.parent = self\n\n    def add_child(self, child_node: \"Node\"):\n        \"\"\"\n        Add a child to the Node.\n\n        Parameters:\n        - child_node: Node to be added as child\n        \"\"\"\n        logger.debug(f\"Adding child node to {self}\")\n        self.children.append(child_node)\n        child_node.parent = self\n        logger.trace(f\"Child added. Node now has {len(self.children)} children\")\n\n    def remove_child(self, child_node: \"Node\") -&gt; \"Node\":\n        logger.debug(f\"Removing child node {child_node} from {self}\")\n        self.children.remove(child_node)\n        child_node.parent = None\n        logger.trace(f\"Child removed. Node now has {len(self.children)} children\")\n        return child_node\n\n    def replace_child(self, child, replacement_node):\n        \"\"\"\n        Replaces child in place. No add child or remove child is called, so no add/remove adjustments are made.\n        \"\"\"\n        logger.debug(f\"Replacing child node {child} with {replacement_node} in {self}\")\n\n        if replacement_node.parent is not None:\n            logger.error(f\"Replacement node {replacement_node} already has a parent\")\n            raise ValueError(\"Replacement node already has a parent\")\n\n        ix = self.children.index(child)\n        self.children[ix] = replacement_node\n\n        child.parent = None\n        replacement_node.parent = self\n        logger.trace(f\"Child replaced at index {ix}\")\n\n    def get_nodes(self):\n        \"\"\"\n        Get all nodes in the tree created by node and its subnodes.\n        Returns:\n        - List of all nodes in the tree in breadth-first order\n        \"\"\"\n        nodes = [self]\n        current_level = [self]\n\n        while current_level:\n            next_level = []\n            for node in current_level:\n                next_level.extend(node.children)\n            nodes.extend(next_level)\n            current_level = next_level\n\n        return nodes\n\n    def copy(self):\n        \"\"\"\n        Create a copy of the node.\n        It's children and parent references are not copied.\n\n        Returns:\n        - Copy of the node\n        \"\"\"\n        return Node()\n\n    def copy_subtree(self):\n        \"\"\"\n        Copy the subtree rooted at this node.\n        Does not call \"add_child\" method to avoid any other operations like weight adjustments.\n        Directly sets parent and children references.\n        Returns:\n        - Copy of the subtree rooted at this node\n        \"\"\"\n        logger.debug(f\"Creating copy of subtree rooted at {self}\")\n        self_copy = self.copy()\n\n        for child in self.children:\n            logger.trace(f\"Copying child subtree: {child}\")\n            child_copy = child.copy_subtree()\n            self_copy.children.append(child_copy)  # not \"append_child\" to avoid any other operations\n            child_copy.parent = self_copy\n\n        logger.trace(f\"Subtree copy complete with {len(self_copy.children)} children\")\n        return self_copy\n\n    def calculate(self):\n        \"\"\"\n        Abstract method for calculation logic.\n\n        Returns:\n        - Calculated Tensor object\n        \"\"\"\n        raise NotImplementedError(\"Calculate method not implemented\")\n\n    @property\n    def code(self) -&gt; str:\n        \"\"\"\n        Identifies node for duplicate handling.\n\n        Returns:\n        - Code string\n        \"\"\"\n        return f\"Node at {hex(id(self))}\"\n\n    def __repr__(self):\n        return self.code\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.code","title":"<code>code</code>  <code>property</code>","text":"<p>Identifies node for duplicate handling.</p> <p>Returns: - Code string</p>"},{"location":"api/nodes/#okapi.node.Node.__init__","title":"<code>__init__(children=None)</code>","text":"<p>Create a node</p> <p>Parameters:</p> Name Type Description Default <code>children</code> <code>Optional[Sequence[Node]]</code> <p>An optional list like sequence of children of the node</p> <code>None</code> Source code in <code>okapi/node.py</code> <pre><code>def __init__(self, children: Optional[Sequence[\"Node\"]] = None):\n    \"\"\"\n    Create a node\n\n    Args:\n        children (Optional[Sequence[\"Node\"]]): An optional list like sequence of children of the node\n    \"\"\"\n    self.parent: Union[Node, None] = None\n    self.children: List[Node] = list(children) if children is not None else []\n\n    for child in self.children:\n        child.parent = self\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.add_child","title":"<code>add_child(child_node)</code>","text":"<p>Add a child to the Node.</p> <p>Parameters: - child_node: Node to be added as child</p> Source code in <code>okapi/node.py</code> <pre><code>def add_child(self, child_node: \"Node\"):\n    \"\"\"\n    Add a child to the Node.\n\n    Parameters:\n    - child_node: Node to be added as child\n    \"\"\"\n    logger.debug(f\"Adding child node to {self}\")\n    self.children.append(child_node)\n    child_node.parent = self\n    logger.trace(f\"Child added. Node now has {len(self.children)} children\")\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.calculate","title":"<code>calculate()</code>","text":"<p>Abstract method for calculation logic.</p> <p>Returns: - Calculated Tensor object</p> Source code in <code>okapi/node.py</code> <pre><code>def calculate(self):\n    \"\"\"\n    Abstract method for calculation logic.\n\n    Returns:\n    - Calculated Tensor object\n    \"\"\"\n    raise NotImplementedError(\"Calculate method not implemented\")\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.copy","title":"<code>copy()</code>","text":"<p>Create a copy of the node. It's children and parent references are not copied.</p> <p>Returns: - Copy of the node</p> Source code in <code>okapi/node.py</code> <pre><code>def copy(self):\n    \"\"\"\n    Create a copy of the node.\n    It's children and parent references are not copied.\n\n    Returns:\n    - Copy of the node\n    \"\"\"\n    return Node()\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.copy_subtree","title":"<code>copy_subtree()</code>","text":"<p>Copy the subtree rooted at this node. Does not call \"add_child\" method to avoid any other operations like weight adjustments. Directly sets parent and children references. Returns: - Copy of the subtree rooted at this node</p> Source code in <code>okapi/node.py</code> <pre><code>def copy_subtree(self):\n    \"\"\"\n    Copy the subtree rooted at this node.\n    Does not call \"add_child\" method to avoid any other operations like weight adjustments.\n    Directly sets parent and children references.\n    Returns:\n    - Copy of the subtree rooted at this node\n    \"\"\"\n    logger.debug(f\"Creating copy of subtree rooted at {self}\")\n    self_copy = self.copy()\n\n    for child in self.children:\n        logger.trace(f\"Copying child subtree: {child}\")\n        child_copy = child.copy_subtree()\n        self_copy.children.append(child_copy)  # not \"append_child\" to avoid any other operations\n        child_copy.parent = self_copy\n\n    logger.trace(f\"Subtree copy complete with {len(self_copy.children)} children\")\n    return self_copy\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.get_nodes","title":"<code>get_nodes()</code>","text":"<p>Get all nodes in the tree created by node and its subnodes. Returns: - List of all nodes in the tree in breadth-first order</p> Source code in <code>okapi/node.py</code> <pre><code>def get_nodes(self):\n    \"\"\"\n    Get all nodes in the tree created by node and its subnodes.\n    Returns:\n    - List of all nodes in the tree in breadth-first order\n    \"\"\"\n    nodes = [self]\n    current_level = [self]\n\n    while current_level:\n        next_level = []\n        for node in current_level:\n            next_level.extend(node.children)\n        nodes.extend(next_level)\n        current_level = next_level\n\n    return nodes\n</code></pre>"},{"location":"api/nodes/#okapi.node.Node.replace_child","title":"<code>replace_child(child, replacement_node)</code>","text":"<p>Replaces child in place. No add child or remove child is called, so no add/remove adjustments are made.</p> Source code in <code>okapi/node.py</code> <pre><code>def replace_child(self, child, replacement_node):\n    \"\"\"\n    Replaces child in place. No add child or remove child is called, so no add/remove adjustments are made.\n    \"\"\"\n    logger.debug(f\"Replacing child node {child} with {replacement_node} in {self}\")\n\n    if replacement_node.parent is not None:\n        logger.error(f\"Replacement node {replacement_node} already has a parent\")\n        raise ValueError(\"Replacement node already has a parent\")\n\n    ix = self.children.index(child)\n    self.children[ix] = replacement_node\n\n    child.parent = None\n    replacement_node.parent = self\n    logger.trace(f\"Child replaced at index {ix}\")\n</code></pre>"},{"location":"api/nodes/#value-node","title":"Value Node","text":"<p>The <code>ValueNode</code> class represents a node that holds tensor data (model predictions).</p> <pre><code>from okapi.node import ValueNode\n</code></pre> <p>               Bases: <code>Node</code></p> <p>Represents a Value Node in a computational tree.</p> <p>A Value Node holds a specific value or tensor.</p> Source code in <code>okapi/node.py</code> <pre><code>class ValueNode(Node):\n    \"\"\"\n    Represents a Value Node in a computational tree.\n\n    A Value Node holds a specific value or tensor.\n    \"\"\"\n\n    def __init__(self, children: Optional[Sequence[\"OperatorNode\"]], value, id: Union[int, str]):\n        super().__init__(children)\n        self.value = value\n        self.evaluation: None | Tensor = None\n        self.id = id\n\n    def calculate(self):\n        logger.trace(f\"Calculating value for ValueNode {self.id}\")\n        if self.children:\n            for child in self.children:\n                logger.trace(f\"Calculating from child node: {child}\")\n                self.evaluation = child.calculate()\n        else:\n            self.evaluation = self.value\n            logger.trace(f\"Using direct value for node {self.id}\")\n        return self.evaluation\n\n    def __str__(self):\n        return f\"ValueNode with value at: {hex(id(self.value))}\"  # and evaluation: {self.evaluation}\"\n\n    def add_child(self, child_node):\n        logger.debug(f\"Adding child to ValueNode {self.id}\")\n        super().add_child(child_node)\n        self.evaluation = None\n        logger.debug(\"Child added and evaluation reset\")\n\n    def copy(self) -&gt; \"ValueNode\":\n        return ValueNode(None, self.value, self.id)\n\n    @property\n    def code(self) -&gt; str:\n        return f\"VN[{self.id}]\"\n</code></pre>"},{"location":"api/nodes/#operator-node","title":"Operator Node","text":"<p>The <code>OperatorNode</code> class is the base class for all operation nodes that define how to combine tensor data.</p> <pre><code>from okapi.node import OperatorNode\n</code></pre> <p>               Bases: <code>Node</code></p> <p>Abstract Base Class for an Operator Node in a computational tree.</p> <p>Reduction Operator Nodes are specialized Operator Nodes capable of performing reduction operations like mean, max, min, etc., on tensors.</p> Source code in <code>okapi/node.py</code> <pre><code>class OperatorNode(Node):\n    \"\"\"\n    Abstract Base Class for an Operator Node in a computational tree.\n\n    Reduction Operator Nodes are specialized Operator Nodes capable\n    of performing reduction operations like mean, max, min, etc., on tensors.\n    \"\"\"\n\n    def __init__(\n        self,\n        children: Optional[Sequence[ValueNode]],\n    ):\n        super().__init__(children)\n\n    def calculate(self):\n        logger.trace(f\"Calculating value for {self.__class__.__name__}\")\n        concat = self._concat()\n        logger.trace(f\"Concatenated tensor shape: {B.shape(concat)}\")\n        post_op = self.op(concat)\n        logger.trace(f\"Post-operation tensor shape: {B.shape(post_op)}\")\n        postprocessed = PF(post_op)  # by default passthrough, may change for different tasks\n        return postprocessed\n\n    def _concat(self):\n        assert self.parent is not None, \"OperatorNode must have a parent to be calculated\"\n        parent: ValueNode = cast(ValueNode, self.parent)\n        parent_eval = parent.evaluation if parent.evaluation is not None else parent.value\n        logger.trace(f\"Concatenating parent and {len(self.children)} children tensors\")\n        return B.concat(\n            [B.unsqueeze(parent_eval, axis=0)] + [B.unsqueeze(child.calculate(), axis=0) for child in self.children],\n            axis=0,\n        )\n\n    @staticmethod\n    def create_node(children):\n        raise NotImplementedError()\n\n    def op(self, x):\n        return x\n</code></pre>"},{"location":"api/nodes/#specific-operator-nodes","title":"Specific Operator Nodes","text":"<p>Various specific operator node implementations are provided:</p>"},{"location":"api/nodes/#mean-node","title":"Mean Node","text":"<p>               Bases: <code>OperatorNode</code></p> <p>Represents a Mean Node in a computational tree.</p> <p>A Mean Node computes the mean along a specified axis of a tensor.</p> Source code in <code>okapi/node.py</code> <pre><code>class MeanNode(OperatorNode):\n    \"\"\"\n    Represents a Mean Node in a computational tree.\n\n    A Mean Node computes the mean along a specified axis of a tensor.\n    \"\"\"\n\n    def __init__(self, children: Optional[Sequence[ValueNode]]):\n        super().__init__(children)\n\n    def __str__(self) -&gt; str:\n        return \"MeanNode\"\n\n    def copy(self):\n        return MeanNode(None)\n\n    @property\n    def code(self) -&gt; str:\n        return \"MN\"\n\n    def op(self, x):\n        return B.mean(x, axis=0)\n\n    @staticmethod\n    def create_node(children):  # TODO: it could be derived from simple vs parametrized OperatorNode\n        return MeanNode(children)\n</code></pre>"},{"location":"api/nodes/#weighted-mean-node","title":"Weighted Mean Node","text":"<p>               Bases: <code>OperatorNode</code></p> <p>Represents a Weighted Mean Node in a computational tree.</p> <p>A Weighted Mean Node computes the mean of a tensor, but with different weights applied to each element.</p> Source code in <code>okapi/node.py</code> <pre><code>class WeightedMeanNode(OperatorNode):\n    \"\"\"\n    Represents a Weighted Mean Node in a computational tree.\n\n    A Weighted Mean Node computes the mean of a tensor,\n    but with different weights applied to each element.\n    \"\"\"\n\n    def __init__(\n        self,\n        children: Optional[Sequence[ValueNode]],\n        weights: List[float],\n    ):\n        logger.debug(f\"Creating WeightedMeanNode with {len(weights) if weights else 0} weights\")\n        self._weights = weights\n        super().__init__(children)\n\n        self._weight_sum_assertion()\n        logger.trace(f\"WeightedMeanNode initialized with weights: {weights}\")\n\n    def op(self, x):\n        weight_shape = (-1, *([1] * (len(x.shape) - 1)))\n        w = B.reshape(self.weights, weight_shape)\n        x = x * w\n        x = B.sum(x, axis=0)\n        return x\n\n    def copy(self):\n        return WeightedMeanNode([], [x for x in self._weights])  # this needs to be rethought\n\n    def add_child(self, child_node: Node):\n        logger.debug(f\"Adding child to WeightedMeanNode with current weights: {self._weights}\")\n        assert isinstance(child_node, ValueNode)\n        child_weight = np.random.uniform(0, 1)\n        adj = 1.0 - child_weight\n\n        logger.trace(f\"Generated child weight: {child_weight}, adjustment factor: {adj}\")\n        for i, val in enumerate(self._weights):\n            self._weights[i] = val * adj\n        self._weights.append(child_weight)\n        self._weight_sum_assertion()\n\n        super().add_child(child_node)\n        self._weight_length_assertion()\n        logger.debug(f\"Child added, new weights: {self._weights}\")\n\n    def remove_child(self, child_node: Node):\n        logger.debug(f\"Removing child from WeightedMeanNode with current weights: {self._weights}\")\n        assert isinstance(child_node, ValueNode), \"Child node of WMN must be a ValueNode\"\n\n        child_ix = self.children.index(child_node)\n        adj = 1.0 - self._weights[child_ix + 1]  # adjust for parent weight being first\n        weight_removed = self._weights[child_ix + 1]\n\n        if abs(adj) &lt; 1e-10:\n            raise ValueError(\n                f\"Cannot remove child with weight {weight_removed:.6f} as it would result in division by zero. \"\n                f\"This child has nearly all the weight (sum of remaining weights is ~0).\"\n            )\n\n        self._weights.pop(child_ix + 1)\n\n        logger.trace(f\"Removed weight at index {child_ix + 1} with value {weight_removed}, adjustment factor: {adj}\")\n\n        super().remove_child(child_node)\n\n        for i, val in enumerate(self._weights):\n            self._weights[i] = val / adj\n\n        self._weight_sum_assertion()\n        self._weight_length_assertion()\n\n        logger.debug(f\"Child removed, new weights: {self._weights}\")\n        return child_node\n\n    def replace_child(self, child, replacement_node):\n        super().replace_child(child, replacement_node)\n        self._weight_length_assertion()\n\n    def calculate(self):\n        self._weight_length_assertion()\n        self._weight_sum_assertion()\n        return super().calculate()\n\n    def __str__(self) -&gt; str:\n        return f\"WeightedMeanNode with weights: {B.to_numpy(B.tensor(self._weights)).round(2)}\"\n\n    @property\n    def code(self) -&gt; str:\n        return \"WMN\"\n\n    @property\n    def weights(self):\n        w = B.tensor(self._weights)\n        return w\n\n    @staticmethod\n    def create_node(children: Sequence[ValueNode]):  # TODO: add tests for that function\n        logger.debug(f\"Creating WeightedMeanNode with {len(children)} children\")\n        if len(children) == 0:\n            weights = [1.0]\n            logger.trace(\"No children, setting weight to [1.0]\")\n        elif len(children) == 1:\n            parent_weight = np.random.uniform(0, 1)\n            weights = [parent_weight, 1 - parent_weight]\n            logger.trace(f\"One child, weights: [{parent_weight}, {1 - parent_weight}]\")\n        else:\n            weights = [np.random.uniform(0, 1)]  # initial weight for parent\n            weight_left = 1 - weights[0]\n            logger.trace(f\"Multiple children, parent weight: {weights[0]}, remaining: {weight_left}\")\n\n            for i in range(len(children) - 1):\n                weights.append(np.random.uniform(0, weight_left))\n                weight_left -= weights[-1]\n                logger.trace(f\"Child {i + 1} weight: {weights[-1]}, remaining: {weight_left}\")\n\n            weights.append(weight_left)\n            logger.trace(f\"Final child weight: {weight_left}\")\n\n        node = WeightedMeanNode(children, weights)\n        logger.debug(f\"Created WeightedMeanNode with weights: {weights}\")\n        return node\n\n    def _weight_sum_assertion(self):\n        weight_sum = np.sum(self._weights)\n        if not np.isclose(weight_sum, 1):\n            logger.error(f\"Weights sum to {weight_sum}, not 1.0: {self._weights}\")\n            assert np.isclose(weight_sum, 1), \"Weights do not sum to 1\"\n        logger.trace(f\"Weight sum assertion passed: {weight_sum}\")\n\n    def _weight_length_assertion(self):\n        expected_length = len(self.children) + 1\n        actual_length = len(self._weights)\n        if actual_length != expected_length:\n            logger.error(f\"Weight array length ({actual_length}) does not match expected {expected_length}\")\n            assert actual_length == expected_length, \"Length of weight array is different than number of adjacent nodes\"\n        logger.trace(f\"Weight length assertion passed: {actual_length}\")\n</code></pre>"},{"location":"api/nodes/#min-node","title":"Min Node","text":"<p>               Bases: <code>OperatorNode</code></p> <p>Represents a Min Node in a computational tree.</p> <p>A Min Node computes the minimum value along a specified axis of a tensor.</p> Source code in <code>okapi/node.py</code> <pre><code>class MinNode(OperatorNode):\n    \"\"\"\n    Represents a Min Node in a computational tree.\n\n    A Min Node computes the minimum value along a specified axis of a tensor.\n    \"\"\"\n\n    def __init__(self, children: Optional[Sequence[ValueNode]]):\n        super().__init__(children)\n\n    def __str__(self) -&gt; str:\n        return \"MinNode\"\n\n    def copy(self):\n        return MinNode(None)\n\n    @property\n    def code(self) -&gt; str:\n        return \"MIN\"\n\n    def op(self, x):\n        return B.min(x, axis=0)\n\n    def adjust_params(self):\n        return\n\n    @staticmethod\n    def create_node(children):\n        return MinNode(children)\n</code></pre>"},{"location":"api/nodes/#max-node","title":"Max Node","text":"<p>               Bases: <code>OperatorNode</code></p> <p>Represents a Max Node in a computational tree.</p> <p>A Max Node computes the maximum value along a specified axis of a tensor.</p> Source code in <code>okapi/node.py</code> <pre><code>class MaxNode(OperatorNode):\n    \"\"\"\n    Represents a Max Node in a computational tree.\n\n    A Max Node computes the maximum value along a specified axis of a tensor.\n    \"\"\"\n\n    def __init__(self, children: Optional[Sequence[ValueNode]]):\n        super().__init__(children)\n\n    def __str__(self) -&gt; str:\n        return \"MaxNode\"\n\n    def copy(self):\n        return MaxNode(None)\n\n    @property\n    def code(self) -&gt; str:\n        return \"MAX\"\n\n    def op(self, x):\n        return B.max(x, axis=0)\n\n    def adjust_params(self):\n        return\n\n    @staticmethod\n    def create_node(children):\n        return MaxNode(children)\n</code></pre>"},{"location":"api/nodes/#utility-functions","title":"Utility Functions","text":"Source code in <code>okapi/node.py</code> <pre><code>def check_if_both_types_values(node1, node2):\n    if not isinstance(node1, type):\n        node1 = type(node1)\n    if not isinstance(node2, type):\n        node2 = type(node2)\n\n    return issubclass(node1, ValueNode) and issubclass(node2, ValueNode)\n</code></pre> Source code in <code>okapi/node.py</code> <pre><code>def check_if_both_types_operators(node1, node2):\n    if not isinstance(node1, type):\n        node1 = type(node1)\n    if not isinstance(node2, type):\n        node2 = type(node2)\n    return issubclass(node1, OperatorNode) and issubclass(node2, OperatorNode)\n</code></pre> Source code in <code>okapi/node.py</code> <pre><code>def check_if_both_types_same_node_variant(node1, node2):\n    if not isinstance(node1, type):\n        node1 = type(node1)\n    if not isinstance(node2, type):\n        node2 = type(node2)\n    return check_if_both_types_operators(node1, node2) or check_if_both_types_values(node1, node2)\n</code></pre>"},{"location":"api/operators/","title":"Operators API","text":"<p>This section documents the operator aliases provided by OKAPI for easier usage.</p> <p>Operator aliases provide convenient access to different operator node types.</p> <pre><code>from okapi.operators import MEAN, MIN, MAX, WEIGHTED_MEAN\n</code></pre> <p>Provides convenient aliases for operator node types.</p> <p>This module exposes the various operator node types from okapi.node with simpler names for easier importing and usage.</p>"},{"location":"api/utilities/","title":"Utilities API","text":"<p>This section documents the utility components of OKAPI.</p>"},{"location":"api/utilities/#fitness-functions","title":"Fitness Functions","text":"<p>Functions for evaluating the fitness of trees.</p> <pre><code>from okapi.fitness import average_precision_fitness, roc_auc_score_fitness\n</code></pre>"},{"location":"api/utilities/#okapi.fitness.accuracy_fitness","title":"<code>accuracy_fitness(tree, gt, task='binary')</code>","text":"<p>Calculate the Accuracy score as a fitness measure using torchmetrics.</p> <p>Accuracy is the proportion of correct predictions among the total number of cases processed. This implementation supports binary, multiclass, and multilabel classification.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree whose evaluation will be compared against ground truth</p> required <code>gt</code> <code>Tensor</code> <p>Ground truth tensor containing labels</p> required <code>task</code> <code>Literal['binary', 'multiclass', 'multilabel']</code> <p>Classification task type: - 'binary': Binary classification (default) - 'multiclass': Multiclass classification - 'multilabel': Multilabel classification</p> <code>'binary'</code> <p>Returns:</p> Type Description <code>float</code> <p>Accuracy score as a float between 0 and 1 (higher is better)</p> Source code in <code>okapi/fitness.py</code> <pre><code>def accuracy_fitness(tree: Tree, gt: Tensor, task: Literal[\"binary\", \"multiclass\", \"multilabel\"] = \"binary\") -&gt; float:\n    \"\"\"\n    Calculate the Accuracy score as a fitness measure using torchmetrics.\n\n    Accuracy is the proportion of correct predictions among the total number of cases processed.\n    This implementation supports binary, multiclass, and multilabel classification.\n\n    Args:\n        tree: The tree whose evaluation will be compared against ground truth\n        gt: Ground truth tensor containing labels\n        task: Classification task type:\n            - 'binary': Binary classification (default)\n            - 'multiclass': Multiclass classification\n            - 'multilabel': Multilabel classification\n\n    Returns:\n        Accuracy score as a float between 0 and 1 (higher is better)\n    \"\"\"\n    from torchmetrics.classification import Accuracy\n\n    # Ensure inputs are PyTorch tensors\n    if not isinstance(tree.evaluation, torch.Tensor):\n        pred = torch.tensor(B.to_numpy(tree.evaluation))\n    else:\n        pred = tree.evaluation\n\n    if not isinstance(gt, torch.Tensor):\n        gt = torch.tensor(B.to_numpy(gt))\n\n    # Infer number of classes from ground truth\n    num_classes = _infer_num_classes(gt, task)\n    gt = gt.squeeze().int()\n\n    # Create metric with appropriate parameters based on task\n    if task == \"multiclass\":\n        metric = Accuracy(task=task, num_classes=num_classes)\n    elif task == \"multilabel\":\n        metric = Accuracy(task=task, num_labels=num_classes)\n    else:  # binary\n        metric = Accuracy(task=task)\n\n    # Calculate and return the score\n    return metric(pred, gt).item()\n</code></pre>"},{"location":"api/utilities/#okapi.fitness.average_precision_fitness","title":"<code>average_precision_fitness(tree, gt, task='binary')</code>","text":"<p>Calculate the Average Precision (AP) score as a fitness measure using torchmetrics.</p> <p>Average Precision summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight. This implementation supports binary, multiclass, and multilabel classification.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree whose evaluation will be compared against ground truth</p> required <code>gt</code> <code>Tensor</code> <p>Ground truth tensor containing labels</p> required <code>task</code> <code>Literal['binary', 'multiclass', 'multilabel']</code> <p>Classification task type: - 'binary': Binary classification (default) - 'multiclass': Multiclass classification - 'multilabel': Multilabel classification</p> <code>'binary'</code> <p>Returns:</p> Type Description <code>float</code> <p>Average Precision score as a float between 0 and 1 (higher is better)</p> Source code in <code>okapi/fitness.py</code> <pre><code>def average_precision_fitness(tree: Tree, gt: Tensor, task: Literal[\"binary\", \"multiclass\", \"multilabel\"] = \"binary\") -&gt; float:\n    \"\"\"\n    Calculate the Average Precision (AP) score as a fitness measure using torchmetrics.\n\n    Average Precision summarizes a precision-recall curve as the weighted mean of precisions\n    achieved at each threshold, with the increase in recall from the previous threshold used\n    as the weight. This implementation supports binary, multiclass, and multilabel classification.\n\n    Args:\n        tree: The tree whose evaluation will be compared against ground truth\n        gt: Ground truth tensor containing labels\n        task: Classification task type:\n            - 'binary': Binary classification (default)\n            - 'multiclass': Multiclass classification\n            - 'multilabel': Multilabel classification\n\n    Returns:\n        Average Precision score as a float between 0 and 1 (higher is better)\n    \"\"\"\n    from torchmetrics.classification import AveragePrecision\n\n    # Ensure inputs are PyTorch tensors\n    if not isinstance(tree.evaluation, torch.Tensor):\n        pred = torch.tensor(B.to_numpy(tree.evaluation))\n    else:\n        pred = tree.evaluation\n\n    if not isinstance(gt, torch.Tensor):\n        gt = torch.tensor(B.to_numpy(gt))\n\n    # Infer number of classes from ground truth\n    num_classes = _infer_num_classes(gt, task)\n    gt = gt.squeeze().int()\n\n    # Create metric with appropriate parameters based on task\n    if task == \"multiclass\":\n        metric = AveragePrecision(task=task, num_classes=num_classes)\n    elif task == \"multilabel\":\n        metric = AveragePrecision(task=task, num_labels=num_classes)\n    else:  # binary\n        if pred.shape[1] == 2:\n            pred = pred[:, 1]\n        elif pred.shape[1] == 1:\n            pred = pred.squeeze()\n        else:\n            pass\n        metric = AveragePrecision(task=task)\n\n    # Calculate and return the score\n    return metric(pred, gt).item()\n</code></pre>"},{"location":"api/utilities/#okapi.fitness.roc_auc_score_fitness","title":"<code>roc_auc_score_fitness(tree, gt, task='binary')</code>","text":"<p>Calculate the Area Under the ROC Curve (AUC-ROC) score as a fitness measure using torchmetrics.</p> <p>The AUC-ROC score represents the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance. This implementation supports binary, multiclass, and multilabel classification.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>The tree whose evaluation will be compared against ground truth</p> required <code>gt</code> <code>Tensor</code> <p>Ground truth tensor containing labels</p> required <code>task</code> <code>Literal['binary', 'multiclass', 'multilabel']</code> <p>Classification task type: - 'binary': Binary classification (default) - 'multiclass': Multiclass classification - 'multilabel': Multilabel classification</p> <code>'binary'</code> <p>Returns:</p> Type Description <code>float</code> <p>ROC AUC score as a float between 0 and 1 (higher is better)</p> Source code in <code>okapi/fitness.py</code> <pre><code>def roc_auc_score_fitness(tree: Tree, gt: Tensor, task: Literal[\"binary\", \"multiclass\", \"multilabel\"] = \"binary\") -&gt; float:\n    \"\"\"\n    Calculate the Area Under the ROC Curve (AUC-ROC) score as a fitness measure using torchmetrics.\n\n    The AUC-ROC score represents the probability that a randomly chosen positive instance\n    is ranked higher than a randomly chosen negative instance. This implementation supports\n    binary, multiclass, and multilabel classification.\n\n    Args:\n        tree: The tree whose evaluation will be compared against ground truth\n        gt: Ground truth tensor containing labels\n        task: Classification task type:\n            - 'binary': Binary classification (default)\n            - 'multiclass': Multiclass classification\n            - 'multilabel': Multilabel classification\n\n    Returns:\n        ROC AUC score as a float between 0 and 1 (higher is better)\n    \"\"\"\n    from torchmetrics.classification import AUROC\n\n    # Ensure inputs are PyTorch tensors\n    if not isinstance(tree.evaluation, torch.Tensor):\n        pred = torch.tensor(B.to_numpy(tree.evaluation))\n    else:\n        pred = tree.evaluation\n\n    if not isinstance(gt, torch.Tensor):\n        gt = torch.tensor(B.to_numpy(gt))\n\n    # Infer number of classes from ground truth\n    num_classes = _infer_num_classes(gt, task)\n    gt = gt.squeeze().int()\n\n    # Create metric with appropriate parameters based on task\n    if task == \"multiclass\":\n        metric = AUROC(task=task, num_classes=num_classes)\n    elif task == \"multilabel\":\n        metric = AUROC(task=task, num_labels=num_classes)\n    else:  # binary\n        metric = AUROC(task=task)\n\n    # Calculate and return the score\n    return metric(pred, gt).item()\n</code></pre>"},{"location":"api/utilities/#callbacks","title":"Callbacks","text":"<p>The callback system allows customizing the evolutionary process.</p> <pre><code>from okapi.callback import Callback\n</code></pre> <p>Base class for callbacks that can be triggered during the evolutionary process.</p> <p>Callbacks allow monitoring and potentially modifying the evolution process at specific points: before/after each generation, and at the start/end of the entire evolution. Custom callbacks should inherit from this class and override the methods corresponding to the desired intervention points.</p> Source code in <code>okapi/callback.py</code> <pre><code>class Callback:\n    \"\"\"\n    Base class for callbacks that can be triggered during the evolutionary process.\n\n    Callbacks allow monitoring and potentially modifying the evolution process at\n    specific points: before/after each generation, and at the start/end of the\n    entire evolution. Custom callbacks should inherit from this class and override\n    the methods corresponding to the desired intervention points.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        pass\n\n    def on_generation_end(self, okapi: \"Okapi\") -&gt; None:\n        \"\"\"\n        Called at the end of each generation.\n\n        This hook is triggered after a generation (iteration) of evolution has completed,\n        including selection, crossover, and mutation operations.\n\n        Args:\n            okapi: The Okapi instance running the evolution\n        \"\"\"\n        pass\n\n    def on_evolution_end(self, okapi: \"Okapi\") -&gt; None:\n        \"\"\"\n        Called at the end of the entire evolution process.\n\n        This hook is triggered when all generations have been completed or\n        when the evolution process is manually stopped.\n\n        Args:\n            okapi: The Okapi instance running the evolution\n        \"\"\"\n        pass\n\n    def on_evolution_start(self, okapi: \"Okapi\") -&gt; None:\n        \"\"\"\n        Called at the start of the evolution process.\n\n        This hook is triggered before any generations are run, after the\n        initial population has been created.\n\n        Args:\n            okapi: The Okapi instance running the evolution\n        \"\"\"\n        pass\n\n    def on_generation_start(self, okapi: \"Okapi\") -&gt; None:\n        \"\"\"\n        Called at the start of each generation.\n\n        This hook is triggered before a generation (iteration) of evolution begins,\n        before any selection, crossover, or mutation operations.\n\n        Args:\n            okapi: The Okapi instance running the evolution\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/utilities/#okapi.callback.Callback.on_evolution_end","title":"<code>on_evolution_end(okapi)</code>","text":"<p>Called at the end of the entire evolution process.</p> <p>This hook is triggered when all generations have been completed or when the evolution process is manually stopped.</p> <p>Parameters:</p> Name Type Description Default <code>okapi</code> <code>Okapi</code> <p>The Okapi instance running the evolution</p> required Source code in <code>okapi/callback.py</code> <pre><code>def on_evolution_end(self, okapi: \"Okapi\") -&gt; None:\n    \"\"\"\n    Called at the end of the entire evolution process.\n\n    This hook is triggered when all generations have been completed or\n    when the evolution process is manually stopped.\n\n    Args:\n        okapi: The Okapi instance running the evolution\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/utilities/#okapi.callback.Callback.on_evolution_start","title":"<code>on_evolution_start(okapi)</code>","text":"<p>Called at the start of the evolution process.</p> <p>This hook is triggered before any generations are run, after the initial population has been created.</p> <p>Parameters:</p> Name Type Description Default <code>okapi</code> <code>Okapi</code> <p>The Okapi instance running the evolution</p> required Source code in <code>okapi/callback.py</code> <pre><code>def on_evolution_start(self, okapi: \"Okapi\") -&gt; None:\n    \"\"\"\n    Called at the start of the evolution process.\n\n    This hook is triggered before any generations are run, after the\n    initial population has been created.\n\n    Args:\n        okapi: The Okapi instance running the evolution\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/utilities/#okapi.callback.Callback.on_generation_end","title":"<code>on_generation_end(okapi)</code>","text":"<p>Called at the end of each generation.</p> <p>This hook is triggered after a generation (iteration) of evolution has completed, including selection, crossover, and mutation operations.</p> <p>Parameters:</p> Name Type Description Default <code>okapi</code> <code>Okapi</code> <p>The Okapi instance running the evolution</p> required Source code in <code>okapi/callback.py</code> <pre><code>def on_generation_end(self, okapi: \"Okapi\") -&gt; None:\n    \"\"\"\n    Called at the end of each generation.\n\n    This hook is triggered after a generation (iteration) of evolution has completed,\n    including selection, crossover, and mutation operations.\n\n    Args:\n        okapi: The Okapi instance running the evolution\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/utilities/#okapi.callback.Callback.on_generation_start","title":"<code>on_generation_start(okapi)</code>","text":"<p>Called at the start of each generation.</p> <p>This hook is triggered before a generation (iteration) of evolution begins, before any selection, crossover, or mutation operations.</p> <p>Parameters:</p> Name Type Description Default <code>okapi</code> <code>Okapi</code> <p>The Okapi instance running the evolution</p> required Source code in <code>okapi/callback.py</code> <pre><code>def on_generation_start(self, okapi: \"Okapi\") -&gt; None:\n    \"\"\"\n    Called at the start of each generation.\n\n    This hook is triggered before a generation (iteration) of evolution begins,\n    before any selection, crossover, or mutation operations.\n\n    Args:\n        okapi: The Okapi instance running the evolution\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/utilities/#visualization","title":"Visualization","text":"<p>Functions for visualizing trees.</p> <pre><code>from okapi.draw import draw_tree\n</code></pre> <p>Create a visual representation of a tree structure using Graphviz.</p> <p>This function generates a directed graph visualization of a tree structure, showing nodes and their hierarchical relationships. For ValueNodes, it can optionally display the tensor values and evaluations if they're small enough.</p> <p>Parameters:</p> Name Type Description Default <code>to_draw</code> <code>Node | OperatorNode | Tree | ValueNode</code> <p>The object to visualize (can be a Tree, Node, OperatorNode, or ValueNode)</p> required <code>dot</code> <p>Optional existing Digraph object to add to. If None, a new one is created.</p> <code>None</code> <code>add_val_eval</code> <p>If True, include value and evaluation information for ValueNodes</p> <code>True</code> <p>Returns:</p> Type Description <p>A Graphviz Digraph object representing the tree structure</p> Source code in <code>okapi/draw.py</code> <pre><code>def draw_tree(to_draw: Node | OperatorNode | Tree | ValueNode, dot=None, add_val_eval=True, remove_after_dot=False):\n    \"\"\"\n    Create a visual representation of a tree structure using Graphviz.\n\n    This function generates a directed graph visualization of a tree structure,\n    showing nodes and their hierarchical relationships. For ValueNodes, it can\n    optionally display the tensor values and evaluations if they're small enough.\n\n    Args:\n        to_draw: The object to visualize (can be a Tree, Node, OperatorNode, or ValueNode)\n        dot: Optional existing Digraph object to add to. If None, a new one is created.\n        add_val_eval: If True, include value and evaluation information for ValueNodes\n\n    Returns:\n        A Graphviz Digraph object representing the tree structure\n    \"\"\"\n    node: None | Node | OperatorNode | ValueNode\n    if isinstance(to_draw, Tree):\n        node = to_draw.root\n    else:\n        node = to_draw\n\n    if dot is None:\n        dot = Digraph(comment=\"Tree\")\n        dot.attr('node', shape='box', width='1.0', margin='0.1')\n\n    if isinstance(node, ValueNode):\n        if node.value is not None:\n            value = B.to_numpy(node.value) if (np.prod(node.value.shape) &lt;= 9) else f\"Tensor with memory adress: {hex(id(node.value))}\"\n        else:\n            value = None\n\n        if node.evaluation is not None:\n            evaluation = (\n                B.to_numpy(node.evaluation) if (np.prod(B.shape(node.evaluation)) &lt;= 9) else f\"Tensor with memory adress: {hex(id(node.evaluation))}\"\n            )\n        else:\n            evaluation = None\n\n        display_string = \"Value Node\\n\"\n\n        if node.id is not None:\n            node_id = str(node.id)\n            if remove_after_dot:\n                node_id = node_id.split('.')[0]\n            display_string += f\"Model ID:\\n {node_id}\\n\"\n\n        if add_val_eval:\n            display_string += f\"Value: {value} | Eval: {evaluation}\"\n\n        dot.node(\n            f\"{hex(id(node))}\",\n            display_string,\n        )\n    else:\n        dot.node(f\"{hex(id(node))}\", f\"Op\\n{str(node)}\")\n\n    for child in node.children:\n        draw_tree(child, dot, add_val_eval, remove_after_dot)\n        dot.edge(f\"{hex(id(node))}\", f\"{hex(id(child))}\")\n\n    return dot\n</code></pre>"},{"location":"api/utilities/#postprocessing-functions","title":"Postprocessing Functions","text":"<p>Functions for postprocessing tree outputs.</p> <pre><code>from okapi.functions import scale_vector_to_sum_1, set_multiclass_postprocessing\n</code></pre>"},{"location":"api/utilities/#okapi.functions.scale_vector_to_sum_1","title":"<code>scale_vector_to_sum_1(tensor)</code>","text":"<p>Normalize a tensor so that each vector sums to 1.</p> <p>This function scales each vector in the tensor along the last dimension such that its elements sum to 1, making it suitable for representing probability distributions.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Input tensor to be normalized</p> required <p>Returns:</p> Type Description <p>Normalized tensor where each vector sums to 1</p> Source code in <code>okapi/functions.py</code> <pre><code>def scale_vector_to_sum_1(tensor: Tensor):\n    \"\"\"\n    Normalize a tensor so that each vector sums to 1.\n\n    This function scales each vector in the tensor along the last dimension\n    such that its elements sum to 1, making it suitable for representing\n    probability distributions.\n\n    Args:\n        tensor: Input tensor to be normalized\n\n    Returns:\n        Normalized tensor where each vector sums to 1\n    \"\"\"\n    return tensor / B.unsqueeze(B.sum(tensor, axis=-1), -1)\n</code></pre>"},{"location":"api/utilities/#okapi.functions.set_multiclass_postprocessing","title":"<code>set_multiclass_postprocessing()</code>","text":"<p>Configure the global postprocessing function for multiclass classification.</p> <p>This function sets the global postprocessing to normalize tensor outputs so that they can be interpreted as probability distributions, which is required for multiclass classification tasks. This is important if probas and not logits are an output.</p> Source code in <code>okapi/functions.py</code> <pre><code>def set_multiclass_postprocessing():\n    \"\"\"\n    Configure the global postprocessing function for multiclass classification.\n\n    This function sets the global postprocessing to normalize tensor outputs so that\n    they can be interpreted as probability distributions, which is required for\n    multiclass classification tasks. This is important if probas and not logits are an output.\n    \"\"\"\n    set_postprocessing_function(scale_vector_to_sum_1)\n</code></pre>"},{"location":"api/utilities/#other-utilities","title":"Other Utilities","text":"<p>Additional utility functions.</p> <pre><code>from okapi.utils import Pickle, first_uniques_mask\n</code></pre>"},{"location":"api/utilities/#okapi.utils.Pickle","title":"<code>Pickle</code>","text":"<p>A utility class for serializing and deserializing Python objects using pickle.</p> <p>This class provides static methods for saving objects to files and loading them back, which is particularly useful for persisting tree architectures.</p> Source code in <code>okapi/utils.py</code> <pre><code>class Pickle:\n    \"\"\"\n    A utility class for serializing and deserializing Python objects using pickle.\n\n    This class provides static methods for saving objects to files and loading them back,\n    which is particularly useful for persisting tree architectures.\n    \"\"\"\n\n    @staticmethod\n    def load(path):\n        \"\"\"\n        Load a Python object from a pickle file.\n\n        Args:\n            path: File path to load the object from\n\n        Returns:\n            The deserialized Python object\n        \"\"\"\n        logger.debug(f\"Loading pickle file from: {path}\")\n        try:\n            with open(path, \"rb\") as file:\n                obj = pickle.load(file)\n            logger.debug(f\"Successfully loaded object from {path}\")\n            return obj\n        except Exception as e:\n            logger.error(f\"Failed to load pickle file from {path}: {str(e)}\")\n            raise\n\n    @staticmethod\n    def save(path, obj):\n        \"\"\"\n        Save a Python object to a pickle file.\n\n        Args:\n            path: File path where the object will be saved\n            obj: The Python object to serialize and save\n        \"\"\"\n        logger.debug(f\"Saving object to pickle file: {path}\")\n        try:\n            with open(path, \"wb\") as file:\n                pickle.dump(obj, file)\n            logger.debug(f\"Successfully saved object to {path}\")\n        except Exception as e:\n            logger.error(f\"Failed to save object to {path}: {str(e)}\")\n            raise\n</code></pre>"},{"location":"api/utilities/#okapi.utils.Pickle.load","title":"<code>load(path)</code>  <code>staticmethod</code>","text":"<p>Load a Python object from a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>File path to load the object from</p> required <p>Returns:</p> Type Description <p>The deserialized Python object</p> Source code in <code>okapi/utils.py</code> <pre><code>@staticmethod\ndef load(path):\n    \"\"\"\n    Load a Python object from a pickle file.\n\n    Args:\n        path: File path to load the object from\n\n    Returns:\n        The deserialized Python object\n    \"\"\"\n    logger.debug(f\"Loading pickle file from: {path}\")\n    try:\n        with open(path, \"rb\") as file:\n            obj = pickle.load(file)\n        logger.debug(f\"Successfully loaded object from {path}\")\n        return obj\n    except Exception as e:\n        logger.error(f\"Failed to load pickle file from {path}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api/utilities/#okapi.utils.Pickle.save","title":"<code>save(path, obj)</code>  <code>staticmethod</code>","text":"<p>Save a Python object to a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>File path where the object will be saved</p> required <code>obj</code> <p>The Python object to serialize and save</p> required Source code in <code>okapi/utils.py</code> <pre><code>@staticmethod\ndef save(path, obj):\n    \"\"\"\n    Save a Python object to a pickle file.\n\n    Args:\n        path: File path where the object will be saved\n        obj: The Python object to serialize and save\n    \"\"\"\n    logger.debug(f\"Saving object to pickle file: {path}\")\n    try:\n        with open(path, \"wb\") as file:\n            pickle.dump(obj, file)\n        logger.debug(f\"Successfully saved object to {path}\")\n    except Exception as e:\n        logger.error(f\"Failed to save object to {path}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api/utilities/#okapi.utils.first_uniques_mask","title":"<code>first_uniques_mask(arr)</code>","text":"<p>Create a boolean mask that identifies the first occurrence of each unique item in an array.</p> <p>This function is useful for filtering duplicates from an array while preserving the order of first appearances.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <p>An array-like object to analyze</p> required <p>Returns:</p> Type Description <p>A list of booleans where True indicates the first occurrence of a value and</p> <p>False indicates a duplicate of a previously seen value</p> Source code in <code>okapi/utils.py</code> <pre><code>def first_uniques_mask(arr):\n    \"\"\"\n    Create a boolean mask that identifies the first occurrence of each unique item in an array.\n\n    This function is useful for filtering duplicates from an array while preserving the order\n    of first appearances.\n\n    Args:\n        arr: An array-like object to analyze\n\n    Returns:\n        A list of booleans where True indicates the first occurrence of a value and\n        False indicates a duplicate of a previously seen value\n    \"\"\"\n    logger.trace(f\"Creating unique items mask for array of length {len(arr)}\")\n    mask = []\n    seen = set()\n    unique_count = 0\n\n    for item in arr:\n        if item not in seen:\n            mask.append(True)\n            seen.add(item)\n            unique_count += 1\n        else:\n            mask.append(False)\n\n    logger.trace(f\"Found {unique_count} unique items out of {len(arr)} total items\")\n    return mask\n</code></pre>"},{"location":"api/utilities/#okapi.utils.mark_paths","title":"<code>mark_paths(list_of_paths)</code>","text":"<p>Mark each path in the list with its type (directory or file) or None if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>list_of_paths</code> <p>A list of paths to be marked.</p> required <p>Returns:</p> Type Description <code>tuple[list[str | None], bool]</code> <p>A tuple containing: - A list of strings or None values representing the type of each path. - A boolean indicating whether all paths are of the same type.</p> Source code in <code>okapi/utils.py</code> <pre><code>def mark_paths(list_of_paths) -&gt; tuple[list[str | None], bool]:\n    \"\"\"\n    Mark each path in the list with its type (directory or file) or None if it doesn't exist.\n\n    Args:\n        list_of_paths: A list of paths to be marked.\n\n    Returns:\n        A tuple containing:\n            - A list of strings or None values representing the type of each path.\n            - A boolean indicating whether all paths are of the same type.\n    \"\"\"\n    marked_paths: list[str | None] = []\n\n    for path in list_of_paths:\n        if os.path.exists(path):\n            if os.path.isdir(path):\n                marked_paths.append(\"dir\")\n            else:\n                marked_paths.append(\"file\")\n        else:\n            marked_paths.append(None)\n    all_same = all(item == marked_paths[0] for item in marked_paths)\n    return marked_paths, all_same\n</code></pre>"},{"location":"development/contributing/","title":"Contributing to OKAPI","text":"<p>OKAPI is an open-source project, and contributions are welcome. This document provides guidelines for contributing to the project.</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/damiankucharski/OKAPI.git\ncd OKAPI\n</code></pre> 1.1 Or fork it to be able to send pull requests</p> </li> <li> <p>Install uv if you don't have it already:    <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p> </li> <li> <p>Sync the environment with all dependencies:    <pre><code>uv sync --all-groups --all-extras\n</code></pre></p> </li> </ol> <p>This will automatically:    - Create a virtual environment if needed    - Update the lock file if necessary    - Install the project in editable mode    - Install all dependencies including development dependencies and optional extras</p> <ol> <li>Install pre-commit hooks:    <pre><code>uv run pre-commit install\n</code></pre></li> </ol>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<p>OKAPI uses:</p> <ul> <li>Ruff for code linting and formatting</li> <li>mypy for type checking</li> </ul> <p>Docstrings should follow the Google-style format, which is used throughout the codebase.</p>"},{"location":"development/contributing/#testing","title":"Testing","text":"<p>Run the tests pytest:</p> <pre><code>make test\n</code></pre> <p>Check typing with mypy:</p> <pre><code>make mypy\n</code></pre> <p>Both of these can be run with the following make command:</p> <pre><code>make test_all\n</code></pre> <p>When adding new features, please include tests. If you do not have GNU Make installed, you can just run the commands from the Makefile yourself.</p>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<p>Documentation is written in Markdown and built using MkDocs with the Material theme. API documentation is automatically generated from docstrings using mkdocstrings.</p> <p>To preview the documentation locally:</p> <pre><code>make serve_docs\n</code></pre> <p>Then visit <code>http://127.0.0.1:8000</code> in your browser.</p>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch for your changes</li> <li>Make your changes</li> <li>Run the tests and make sure they pass</li> <li>Update documentation as needed</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you find a bug or have a feature request, please create an issue in the GitHub repository. Please include:</p> <ul> <li>A clear and descriptive title</li> <li>A description of the issue or feature request</li> <li>Steps to reproduce the issue (for bugs)</li> <li>Any relevant code samples, error messages, or screenshots</li> </ul>"}]}